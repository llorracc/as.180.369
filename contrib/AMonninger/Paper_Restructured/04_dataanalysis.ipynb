{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b3f4c21",
   "metadata": {},
   "source": [
    "# Excess Return Analysis: BNPL Stocks and Interest Rate Sensitivity\n",
    "\n",
    "This analysis examines whether BNPL stocks generate excess returns relative to the market, and how these excess returns respond to changes in interest rates. Excess returns are calculated as BNPL stock returns minus market returns (using the S&P 500 as a proxy), which isolates BNPL-specific performance from broader market movements.\n",
    "\n",
    "The Consumer Financial Protection Bureau's 2025 report reveals that BNPL adoption has grown substantially, with 21% of consumers with credit records using BNPL in 2022, up from 18% in 2021. This rapid growth, combined with the sector's sensitivity to funding costs, makes excess return analysis particularly relevant for understanding whether BNPL firms generate returns that compensate investors for their unique risk profile.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48ff2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d76dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e5740",
   "metadata": {},
   "outputs": [],
   "source": [
    "=======\n",
    "# EXCESS RETURN ANALYSIS: Data Loading and Preparation\n",
    "# ============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pandas_datareader.data as web\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'axes.labelsize': 15,\n",
    "    'axes.titlesize': 17,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 13,\n",
    "    'figure.titlesize': 18\n",
    "})\n",
    "\n",
    "print(\"Loading data for excess return analysis...\")\n",
    "\n",
    "# BNPL tickers - Major US-traded BNPL companies per CFPB report and industry analysis\n",
    "# CFPB report covers: Affirm, Afterpay (Block), Klarna, PayPal, Sezzle, and Zip\n",
    "# Using publicly traded US companies: PYPL (PayPal), AFRM (Affirm), SEZL (Sezzle), SQ (Block/Afterpay), KLAR (Klarna)\n",
    "# Note: KLAR IPO'd September 2025, so has limited historical data\n",
    "bnpl_tickers = ['PYPL', 'AFRM', 'SEZL', 'SQ', 'KLAR']\n",
    "\n",
    "# Market benchmark (S&P 500)\n",
    "market_ticker = 'SPY'\n",
    "\n",
    "# Date range\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime(2025, 8, 31)\n",
    "\n",
    "# Fetch BNPL stock returns\n",
    "bnpl_returns = {}\n",
    "for ticker in bnpl_tickers:\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        hist = stock.history(start=start_date, end=end_date)\n",
    "        if not hist.empty:\n",
    "            monthly = hist['Close'].resample('ME').last()\n",
    "            if monthly.index.tz is not None:\n",
    "                monthly.index = monthly.index.tz_localize(None)\n",
    "            returns = monthly.pct_change() * 100\n",
    "            bnpl_returns[ticker] = returns\n",
    "            print(f\"  ✓ Loaded {ticker}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠ Skipping {ticker}: {str(e)[:50]}\")\n",
    "\n",
    "# Fetch market returns\n",
    "try:\n",
    "    market = yf.Ticker(market_ticker)\n",
    "    market_hist = market.history(start=start_date, end=end_date)\n",
    "    if not market_hist.empty:\n",
    "        market_monthly = market_hist['Close'].resample('ME').last()\n",
    "        if market_monthly.index.tz is not None:\n",
    "            market_monthly.index = market_monthly.index.tz_localize(None)\n",
    "        market_returns = market_monthly.pct_change() * 100\n",
    "        print(f\"  ✓ Loaded {market_ticker} (market benchmark)\")\n",
    "except Exception as e:\n",
    "    print(f\"  ⚠ Error loading market data: {str(e)[:50]}\")\n",
    "\n",
    "# Fetch Federal Funds Rate\n",
    "try:\n",
    "    fed_funds = web.DataReader('FEDFUNDS', 'fred', start_date, end_date)\n",
    "    fed_funds_change = fed_funds['FEDFUNDS'].diff()\n",
    "    if fed_funds_change.index.tz is not None:\n",
    "        fed_funds_change.index = fed_funds_change.index.tz_localize(None)\n",
    "    print(f\"  ✓ Loaded Federal Funds Rate data\")\n",
    "except Exception as e:\n",
    "    print(f\"  ⚠ Error loading interest rate data: {str(e)[:50]}\")\n",
    "\n",
    "print(\"\\nData loading complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e355a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Calculate Excess Returns\n",
    "# ============================================================================\n",
    "\n",
    "# Calculate average BNPL return (handling missing data from KLAR's limited history)\n",
    "bnpl_df = pd.DataFrame(bnpl_returns)\n",
    "# Use mean across available stocks for each month (handles KLAR's limited data)\n",
    "avg_bnpl_return = bnpl_df.mean(axis=1, skipna=True)\n",
    "\n",
    "# Ensure indices are timezone-naive and aligned\n",
    "if avg_bnpl_return.index.tz is not None:\n",
    "    avg_bnpl_return.index = avg_bnpl_return.index.tz_localize(None)\n",
    "if market_returns.index.tz is not None:\n",
    "    market_returns.index = market_returns.index.tz_localize(None)\n",
    "\n",
    "# Align to monthly end dates\n",
    "avg_bnpl_return.index = pd.to_datetime(avg_bnpl_return.index).to_period('M').to_timestamp('M')\n",
    "market_returns.index = pd.to_datetime(market_returns.index).to_period('M').to_timestamp('M')\n",
    "\n",
    "# Align fed_funds_change index BEFORE creating DataFrame\n",
    "if fed_funds_change.index.tz is not None:\n",
    "    fed_funds_change.index = fed_funds_change.index.tz_localize(None)\n",
    "fed_funds_change.index = pd.to_datetime(fed_funds_change.index).to_period('M').to_timestamp('M')\n",
    "\n",
    "# Calculate excess returns: BNPL returns minus market returns\n",
    "excess_returns = avg_bnpl_return - market_returns\n",
    "\n",
    "# Create comprehensive dataset by merging on index\n",
    "data = pd.DataFrame({\n",
    "    'bnpl_return': avg_bnpl_return,\n",
    "    'market_return': market_returns,\n",
    "    'excess_return': excess_returns,\n",
    "})\n",
    "\n",
    "# Merge fed_funds_change on index\n",
    "data = data.join(fed_funds_change.to_frame('fed_funds_change'), how='inner')\n",
    "\n",
    "# Drop rows with any missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Recalculate excess returns from aligned data to ensure consistency\n",
    "if len(data) > 0:\n",
    "    excess_returns_aligned = data['excess_return']\n",
    "    \n",
    "    # Calculate summary statistics\n",
    "    excess_mean = excess_returns_aligned.mean()\n",
    "    excess_std = excess_returns_aligned.std()\n",
    "    excess_sharpe = excess_mean / excess_std if excess_std > 0 else np.nan\n",
    "    \n",
    "    # Calculate correlation\n",
    "    excess_market_corr = excess_returns_aligned.corr(data['market_return'])\n",
    "    \n",
    "    # Report which stocks were successfully loaded\n",
    "    loaded_stocks = list(bnpl_returns.keys())\n",
    "    print(f\"\\nBNPL Stocks Loaded: {', '.join(loaded_stocks)}\")\n",
    "    if 'KLAR' in loaded_stocks:\n",
    "        klarna_data = bnpl_returns['KLAR']\n",
    "        print(f\"  Note: KLAR (Klarna) has data from {klarna_data.index.min()} to {klarna_data.index.max()}\")\n",
    "        print(f\"        (IPO'd September 2025 - limited historical data)\")\n",
    "    \n",
    "    print(f\"\\nExcess Return Statistics:\")\n",
    "    print(f\"  Mean excess return: {excess_mean:.2f}% per month\")\n",
    "    print(f\"  Standard deviation: {excess_std:.2f}%\")\n",
    "    print(f\"  Sharpe ratio (monthly): {excess_sharpe:.3f}\")\n",
    "    print(f\"  Correlation with market: {excess_market_corr:.3f}\")\n",
    "    print(f\"  Number of observations: {len(data)}\")\n",
    "    print(f\"\\n  Date range: {data.index.min()} to {data.index.max()}\")\n",
    "else:\n",
    "    print(\"⚠ ERROR: No overlapping data found after merging!\")\n",
    "    print(f\"  BNPL return dates: {avg_bnpl_return.index.min()} to {avg_bnpl_return.index.max()}\")\n",
    "    print(f\"  Market return dates: {market_returns.index.min()} to {market_returns.index.max()}\")\n",
    "    print(f\"  Fed Funds dates: {fed_funds_change.index.min()} to {fed_funds_change.index.max()}\")\n",
    "    excess_mean = np.nan\n",
    "    excess_std = np.nan\n",
    "    excess_sharpe = np.nan\n",
    "    excess_market_corr = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae19c6b",
   "metadata": {},
   "source": [
    "## Excess Return Performance Analysis\n",
    "\n",
    "The excess return analysis reveals important insights about BNPL stock performance relative to the broader market. Excess returns, calculated as BNPL returns minus S&P 500 returns, isolate sector-specific performance from general market movements. This approach is particularly relevant given the rapid growth of the BNPL sector, where the Consumer Financial Protection Bureau (2025) found that 21% of consumers with credit records used BNPL services in 2022, representing a significant increase from 18% in 2021.\n",
    "\n",
    "According to industry statistics from Digital Silk (2025) and Chargeflow (2025), the global BNPL market reached $340 billion in gross merchandise volume in 2024 and is projected to reach $560.1 billion in 2025, with the U.S. market showing particularly strong growth. The U.S. BNPL market is expected to reach $124.82 billion by 2027, reflecting a 20.4% year-over-year growth rate in 2025. The six major providers analyzed by the CFPB—Affirm, Afterpay (now part of Block), Klarna, PayPal, Sezzle, and Zip—collectively processed over 277 million BNPL loans worth approximately $34 billion in 2022. Digital Silk (2025) reports that 86.5 million U.S. consumers used BNPL services in 2024, with shoppers spending $18.2 billion using BNPL during the 2024 holiday season alone. This scale makes understanding excess returns critical for assessing whether BNPL firms generate returns that adequately compensate investors for their unique risk profile, particularly their sensitivity to interest rate changes.\n",
    "\n",
    "### Interest Rate Variable Selection: Testing Alternatives\n",
    "\n",
    "We evaluate multiple interest rate variables to identify the best predictor of BNPL excess returns. While **Federal Funds Rate (FFR)** has strong theoretical justification, we test alternative rates that may more directly capture BNPL funding costs:\n",
    "\n",
    "**Candidate Interest Rate Variables:**\n",
    "\n",
    "1. **Federal Funds Rate (FEDFUNDS)** - Primary monetary policy tool\n",
    "   - **Pros**: Directly affects short-term borrowing costs; BNPL firms rely on warehouse credit facilities, securitization, and commercial paper tied to FFR\n",
    "   - **Cons**: Policy-driven rate that may not perfectly reflect market-determined funding costs\n",
    "\n",
    "2. **3-Month Treasury Rate (DGS3MO)** - Short-term risk-free rate\n",
    "   - **Pros**: Market-determined short-term rate; closely related to commercial paper rates\n",
    "   - **Cons**: Risk-free rate may not capture credit risk premiums BNPL firms face\n",
    "\n",
    "3. **Commercial Paper Rate (CPF3M)** - Short-term corporate funding rate\n",
    "   - **Pros**: Most directly related to BNPL firms' actual funding costs\n",
    "   - **Cons**: May have data availability issues; highly correlated with FFR\n",
    "\n",
    "4. **Prime Rate (PRIME)** - Consumer lending benchmark\n",
    "   - **Pros**: Directly affects consumer credit markets where BNPL competes\n",
    "   - **Cons**: Less directly tied to BNPL's wholesale funding costs\n",
    "\n",
    "5. **Credit Spread (BAA - 10Y Treasury)** - Credit market tightness\n",
    "   - **Pros**: Captures credit risk premiums affecting BNPL borrowing costs\n",
    "   - **Cons**: Not an interest rate per se; measures risk premium rather than base rate\n",
    "\n",
    "We test each variable in a simple regression model and select the one with the highest R² and strongest statistical significance, while maintaining theoretical coherence with BNPL firms' funding structure.\n",
    "\n",
    "### Regression Model Specification: Base Model\n",
    "\n",
    "To test whether BNPL excess returns respond to interest rate changes, we estimate the following baseline regression model:\n",
    "\n",
    "**Excess_Return_t = β₀ + β₁(ΔInterest_Rate_t) + ε_t**\n",
    "\n",
    "Where:\n",
    "- **Excess_Return_t** is the monthly excess return of BNPL stocks relative to the S&P 500 in month t\n",
    "- **ΔInterest_Rate_t** is the month-over-month change in the selected interest rate (Federal Funds Rate, Commercial Paper Rate, or 3-Month Treasury) in month t\n",
    "- **β₀** is the intercept term, representing the average excess return when interest rates are unchanged\n",
    "- **β₁** is the coefficient of interest, measuring the sensitivity of excess returns to interest rate changes\n",
    "- **ε_t** is the error term\n",
    "\n",
    "The null hypothesis is H₀: β₁ = 0, which tests whether BNPL excess returns are independent of interest rate changes. If β₁ < 0, BNPL stocks underperform the market when rates rise, suggesting unique sensitivity to monetary policy. If β₁ > 0, BNPL stocks outperform the market when rates rise, which would be counterintuitive given their funding cost structure.\n",
    "\n",
    "**Theoretical Justification for Interest Rate Sensitivity:**\n",
    "\n",
    "The CFPB (2025) documents that BNPL firms rely on short-term funding markets, with cost of funds increasing in early-to-mid 2022 as interest rates rose. Chargeflow (2025) reports that most major BNPL firms remain unprofitable, challenged by rising credit losses and funding costs, making them particularly vulnerable to interest rate increases. Digital Silk (2025) notes that BNPL transaction fees range from 2-8% (average 4-6%), but provider revenues represent only about 4% of gross merchandise volume, highlighting the thin margins that amplify sensitivity to funding cost changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56715423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Excess Returns vs Interest Rate Changes: Baseline Regression Analysis\n",
    "# ============================================================================\n",
    "\n",
    "# Use the selected interest rate variable (from comparison analysis if available, otherwise FFR)\n",
    "if 'selected_rate_var' in globals():\n",
    "    rate_var = selected_rate_var\n",
    "    rate_name = selected_rate_name\n",
    "else:\n",
    "    rate_var = 'fed_funds_change'\n",
    "    rate_name = 'Federal Funds Rate'\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"BASELINE MODEL: Excess Returns vs {rate_name} Changes\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Prepare data for regression\n",
    "X = data[[rate_var]].values\n",
    "y = data['excess_return'].values\n",
    "\n",
    "# Run regression\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Calculate statistics\n",
    "y_pred = model.predict(X)\n",
    "r2 = model.score(X, y)\n",
    "slope = model.coef_[0]\n",
    "intercept = model.intercept_\n",
    "\n",
    "# Calculate confidence intervals\n",
    "n = len(data)\n",
    "mse = np.mean((y - y_pred) ** 2)\n",
    "se_slope = np.sqrt(mse / np.sum((X.flatten() - X.mean()) ** 2))\n",
    "t_critical = stats.t.ppf(0.975, n - 2)\n",
    "ci_lower = slope - t_critical * se_slope\n",
    "ci_upper = slope + t_critical * se_slope\n",
    "\n",
    "# Calculate p-value\n",
    "t_stat = slope / se_slope\n",
    "p_value = 2 * (1 - stats.t.cdf(abs(t_stat), n - 2))\n",
    "\n",
    "# Store results for narrative\n",
    "excess_regression_results = {\n",
    "    'slope': slope,\n",
    "    'intercept': intercept,\n",
    "    'r2': r2,\n",
    "    'ci_lower': ci_lower,\n",
    "    'ci_upper': ci_upper,\n",
    "    'p_value': p_value,\n",
    "    'n': n,\n",
    "    'rate_var': rate_var,\n",
    "    'rate_name': rate_name\n",
    "}\n",
    "\n",
    "print(f\"\\nBaseline Regression Results:\")\n",
    "print(f\"  Dependent Variable: Excess Return (%)\")\n",
    "print(f\"  Independent Variable: {rate_name} Change (%)\")\n",
    "print(f\"  Slope (β₁): {slope:.2f}\")\n",
    "print(f\"  Intercept (β₀): {intercept:.2f}\")\n",
    "print(f\"  R²: {r2:.4f}\")\n",
    "print(f\"  95% CI: [{ci_lower:.2f}, {ci_upper:.2f}]\")\n",
    "print(f\"  P-value: {p_value:.4f}\")\n",
    "print(f\"  Observations: {n}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(f\"\\n  ✓ Statistically significant at 5% level\")\n",
    "    if slope < 0:\n",
    "        print(f\"  Interpretation: BNPL excess returns decrease by {abs(slope):.2f}% per 1% increase in {rate_name}\")\n",
    "    else:\n",
    "        print(f\"  Interpretation: BNPL excess returns increase by {slope:.2f}% per 1% increase in {rate_name}\")\n",
    "else:\n",
    "    print(f\"\\n  ⚠ Not statistically significant at 5% level\")\n",
    "    print(f\"  Interpretation: No significant relationship detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a61e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Visualization: Excess Returns Over Time and vs Interest Rate Changes\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Excess Returns Over Time\n",
    "ax1 = axes[0]\n",
    "ax1.plot(data.index, data['excess_return'], \n",
    "         linewidth=2.5, color='#2980b9', alpha=0.8, label='BNPL Excess Returns')\n",
    "ax1.axhline(y=0, color='#7f8c8d', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax1.fill_between(data.index, 0, data['excess_return'], \n",
    "                  where=(data['excess_return'] >= 0), alpha=0.2, color='#2ecc71', label='Positive Excess Returns')\n",
    "ax1.fill_between(data.index, 0, data['excess_return'], \n",
    "                  where=(data['excess_return'] < 0), alpha=0.2, color='#e74c3c', label='Negative Excess Returns')\n",
    "\n",
    "ax1.set_xlabel('Date', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Excess Return (%)', fontsize=14, fontweight='bold')\n",
    "ax1.set_title('BNPL Excess Returns Over Time\\n(BNPL Returns - S&P 500 Returns)', \n",
    "              fontsize=16, fontweight='bold', pad=15)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend(loc='best', fontsize=11)\n",
    "\n",
    "# Plot 2: Excess Returns vs Interest Rate Changes\n",
    "ax2 = axes[1]\n",
    "rate_data = data[excess_regression_results['rate_var']]\n",
    "scatter = ax2.scatter(rate_data, data['excess_return'], \n",
    "                      alpha=0.6, s=100, color='#16a085', edgecolors='#0d5d4f', \n",
    "                      linewidth=1.5, zorder=4, label='Monthly Observations')\n",
    "\n",
    "# Regression line\n",
    "x_line = np.linspace(rate_data.min(), rate_data.max(), 100)\n",
    "y_line = intercept + slope * x_line\n",
    "ax2.plot(x_line, y_line, color='#0d5d4f', linewidth=3, \n",
    "         label=f'Regression: y = {intercept:.2f} + {slope:.2f}x', zorder=3)\n",
    "\n",
    "# Confidence interval\n",
    "y_ci_lower = intercept + ci_lower * x_line\n",
    "y_ci_upper = intercept + ci_upper * x_line\n",
    "ax2.fill_between(x_line, y_ci_lower, y_ci_upper, alpha=0.25, color='#2ecc71', \n",
    "                 label='95% Confidence Interval', zorder=2)\n",
    "\n",
    "ax2.axhline(y=0, color='#7f8c8d', linestyle='--', linewidth=1, alpha=0.5, zorder=1)\n",
    "ax2.axvline(x=0, color='#7f8c8d', linestyle='--', linewidth=1, alpha=0.5, zorder=1)\n",
    "\n",
    "ax2.set_xlabel(f'Change in {excess_regression_results[\"rate_name\"]} (%)', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Excess Return (%)', fontsize=14, fontweight='bold')\n",
    "ax2.set_title('Excess Returns vs Interest Rate Changes', \n",
    "              fontsize=16, fontweight='bold', pad=15)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend(loc='best', fontsize=11)\n",
    "\n",
    "# Add statistics text box\n",
    "stats_text = (f'R² = {r2:.3f}\\n'\n",
    "              f'Slope = {slope:.2f}\\n'\n",
    "              f'95% CI: [{ci_lower:.2f}, {ci_upper:.2f}]\\n'\n",
    "              f'P-value = {p_value:.4f}\\n'\n",
    "              f'n = {n}')\n",
    "ax2.text(0.05, 0.95, stats_text, transform=ax2.transAxes, \n",
    "         fontsize=11, verticalalignment='top', fontweight='bold',\n",
    "         bbox=dict(boxstyle='round,pad=0.8', facecolor='#ecf0f1', \n",
    "                  edgecolor='#34495e', linewidth=2, alpha=0.9))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('excess_returns_analysis.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Visualization complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109b1e86",
   "metadata": {},
   "source": [
    "### Market Performance and Risk-Adjusted Returns\n",
    "\n",
    "The analysis of excess returns provides insights into whether BNPL stocks offer superior risk-adjusted returns compared to the broader market. Over the sample period, BNPL stocks generated an average monthly excess return of {excess_mean:.2f}%, with a standard deviation of {excess_std:.2f}%, resulting in a Sharpe ratio of {excess_sharpe:.3f}. The correlation between excess returns and market returns of {excess_market_corr:.3f} indicates that {'BNPL stocks move somewhat independently of the market' if abs(excess_market_corr) < 0.5 else 'BNPL stocks exhibit substantial co-movement with the broader market'}, suggesting that excess returns capture BNPL-specific factors rather than general market trends.\n",
    "\n",
    "This performance must be understood in the context of the sector's rapid growth and evolving risk profile. According to Chargeflow (2025), approximately 34-41% of BNPL users reported making late payments in the past year, with Gen Z users showing an even higher rate of 51%. Digital Silk (2025) reports that 55% of users choose BNPL because it allows them to afford things they otherwise couldn't, and 77.7% of BNPL users relied on at least one financial coping strategy (working extra hours, borrowing money, or using savings) compared to 66.1% of non-users. While the CFPB (2025) found that BNPL default rates remain relatively low at around 2% (compared to 10% for credit cards among the same borrower population), the high late payment rate suggests underlying cash flow stress among users. This creates a dual challenge for BNPL firms: managing credit risk while maintaining growth, particularly as 63% of borrowers have multiple simultaneous loans and 33% borrow across multiple providers, creating \"hidden debt\" that may not be visible in traditional credit records.\n",
    "\n",
    "The sector's sensitivity to interest rates, combined with these credit risk factors, helps explain the volatility observed in excess returns. As interest rates rose from near-zero levels in 2020-2021 to approximately 5% by 2023, BNPL firms faced increasing funding costs while simultaneously navigating regulatory scrutiny. The CFPB's 2025 report notes that regulators are pushing for mandatory credit bureau reporting for BNPL loans, which could reduce \"hidden debt\" but may also limit adoption among subprime borrowers who represent 61% of BNPL originations according to CFPB data. Digital Silk (2025) reports that nearly 30% of adults with credit scores between 620 and 659 used BNPL—roughly three times the rate of those with scores above 720—highlighting the sector's reliance on subprime borrowers. These regulatory changes, combined with profitability pressures—Chargeflow (2025) reports that most major BNPL firms (Klarna, Affirm) remain unprofitable, challenged by rising credit losses and funding costs—create additional uncertainty that may be reflected in excess return volatility.\n",
    "\n",
    "The global BNPL market's scale further contextualizes these findings. Digital Silk (2025) reports that the BNPL market reached $340 billion globally in 2024, with BNPL accounting for 5% of total eCommerce payments worldwide and 6% in the U.S. Chargeflow (2025) projects the market to reach $560.1 billion in GMV by 2025, while provider revenues are significantly smaller at $23.37 billion, highlighting the thin margins that make BNPL firms particularly vulnerable to interest rate changes. This revenue-to-GMV ratio of approximately 4% underscores the sector's reliance on high transaction volumes and low-margin business models, making funding cost increases particularly impactful on profitability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54fa66a",
   "metadata": {},
   "source": [
    "### Implications for Investors and Policy\n",
    "\n",
    "The excess return analysis reveals that BNPL stocks exhibit unique sensitivity to interest rate changes that cannot be fully explained by general market movements. This finding has important implications for both investors and policymakers. For investors, the relationship between interest rate increases and excess returns suggests that BNPL stocks may be particularly vulnerable to monetary tightening, with the statistical significance and economic magnitude depending on the specific time period and market conditions examined.\n",
    "\n",
    "For policymakers, these findings highlight the interconnectedness between monetary policy and fintech sector performance. The CFPB (2025) report emphasizes that BNPL borrowers tend to have higher credit card utilization rates (60-66% versus 34% for non-BNPL users) and hold more unsecured debt across all categories, suggesting that BNPL may be filling gaps left by constrained traditional credit. As the Federal Reserve adjusts interest rates, the impact on BNPL firms' funding costs directly affects their ability to serve consumers, particularly those with subprime or deep subprime credit scores who account for 61% of BNPL originations according to CFPB data.\n",
    "\n",
    "The excess return analysis, combined with the CFPB's findings on consumer debt patterns, suggests that BNPL firms operate in a delicate balance between growth and risk management. While the sector has demonstrated resilience with low default rates relative to credit cards (2% versus 10% according to CFPB data), the high late payment rates (34-41% of users according to Chargeflow 2025) and loan stacking behavior documented by regulators raise questions about long-term sustainability, especially as interest rates normalize and regulatory oversight increases. Chargeflow (2025) notes that BNPL transaction fees range from 2-8% (average 4-6%), exceeding typical credit card fees of about 2%, which may create additional pressure on merchants and consumers as funding costs rise.\n",
    "\n",
    "Understanding how excess returns respond to interest rate changes provides valuable information for assessing whether current stock valuations adequately reflect these risks. The global BNPL market's projected growth to $560.1 billion in GMV by 2025, combined with provider revenues of only $23.37 billion, highlights the sector's thin margins and vulnerability to funding cost increases. As regulatory harmonization accelerates in 2025-2026, particularly in the U.S., EU, and Australia, compliance costs may further squeeze margins, making interest rate sensitivity an increasingly important factor for investors and policymakers to monitor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "control_variable_selection_interpretation",
   "metadata": {},
   "source": [
    "### Control Variable Selection: Systematic Testing Results and Interpretation\n",
    "\n",
    "The systematic testing process evaluated **15 different 5-variable model specifications**, each consisting of the selected interest rate variable (Prime Rate) plus a unique combination of 4 control variables. The results above show the top 5 performing models ranked by adjusted R², revealing which combinations of control variables best explain BNPL excess returns.\n",
    "\n",
    "**Model Selection Results:**\n",
    "\n",
    "The testing process reveals that certain combinations of control variables consistently outperform others. The top-performing model achieves an adjusted R² of approximately 0.1455, representing a substantial improvement over the baseline model's R² of approximately 0.05. This improvement demonstrates that multiple economic channels jointly determine BNPL excess returns, not just interest rate sensitivity alone.\n",
    "\n",
    "**Selected Model Variables:**\n",
    "\n",
    "The model selection algorithm identified the optimal combination of control variables that, together with Prime Rate, maximizes adjusted R². The selected model includes Prime Rate plus the **four control variables** shown in the \"SELECTED BEST MODEL\" output above. These variables were chosen entirely through systematic testing, ensuring that our model captures the most empirically relevant economic channels affecting BNPL performance.\n",
    "\n",
    "**Interpretation of Selected Control Variables:**\n",
    "\n",
    "Each control variable included in the selected model represents a distinct economic mechanism:\n",
    "\n",
    "- **VIX Change**: When included, captures market volatility and risk sentiment effects. Chargeflow (2025) notes that BNPL firms face profitability pressures that amplify market sentiment, making volatility particularly relevant for fintech stocks.\n",
    "\n",
    "- **Consumer Confidence Change**: When included, captures forward-looking spending intentions. Digital Silk (2025) reports that 33.6% of Millennials and 26.4% of Gen Z use BNPL, suggesting that consumer sentiment directly affects BNPL adoption and usage.\n",
    "\n",
    "- **Disposable Income Growth**: When included, captures the income channel. CFPB (2025) documents that income variability increased sharply 2021-2022 and 57.9% of BNPL users experienced income disruptions, making income dynamics particularly relevant.\n",
    "\n",
    "- **Personal Saving Rate Change**: When included, captures financial vulnerability patterns. CFPB (2025) found that 77.7% of BNPL users relied on financial coping strategies and 55% choose BNPL to afford things they otherwise couldn't, suggesting that saving behavior is a key indicator of BNPL demand.\n",
    "\n",
    "- **Retail Sales Growth**: When included, captures the consumer spending channel. Digital Silk (2025) reports that BNPL users spend 6% more online than non-BNPL shoppers and $18.2 billion was spent using BNPL during the 2024 holiday season alone.\n",
    "\n",
    "- **Credit Spread Change**: When included, captures credit market tightness affecting BNPL firms' borrowing costs. This is particularly relevant given that 61% of BNPL borrowers are subprime or deep subprime according to CFPB (2025), making credit market conditions crucial for BNPL firms.\n",
    "\n",
    "**Model Comparison:**\n",
    "\n",
    "Comparing the top 5 models reveals patterns in which variables contribute most to explaining BNPL excess returns. The consistency of certain variables across top-performing models (such as VIX Change and Consumer Confidence Change appearing in multiple top models) suggests these channels are particularly important for BNPL stock performance. The systematic selection process ensures that only the most empirically relevant variables are included, avoiding overfitting while capturing the key economic mechanisms affecting BNPL excess returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afba8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Refined Model: Load Additional Control Variables\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Loading additional control variables for refined model...\")\n",
    "\n",
    "try:\n",
    "    # VIX (Market Volatility)\n",
    "    vix = yf.Ticker('^VIX')\n",
    "    vix_hist = vix.history(start=start_date, end=end_date)\n",
    "    if not vix_hist.empty:\n",
    "        vix_monthly = vix_hist['Close'].resample('ME').last()\n",
    "        if vix_monthly.index.tz is not None:\n",
    "            vix_monthly.index = vix_monthly.index.tz_localize(None)\n",
    "        vix_change = vix_monthly.pct_change() * 100\n",
    "        print(\"  ✓ Loaded VIX data\")\n",
    "    else:\n",
    "        vix_change = None\n",
    "        print(\"  ⚠ VIX data not available\")\n",
    "except Exception as e:\n",
    "    vix_change = None\n",
    "    print(f\"  ⚠ Error loading VIX: {str(e)[:50]}\")\n",
    "\n",
    "try:\n",
    "    # Retail Sales (RSAFS)\n",
    "    retail_sales = web.DataReader('RSAFS', 'fred', start_date, end_date)\n",
    "    retail_sales_change = retail_sales['RSAFS'].pct_change() * 100\n",
    "    if retail_sales_change.index.tz is not None:\n",
    "        retail_sales_change.index = retail_sales_change.index.tz_localize(None)\n",
    "    retail_sales_change.index = pd.to_datetime(retail_sales_change.index).to_period('M').to_timestamp('M')\n",
    "    print(\"  ✓ Loaded Retail Sales data\")\n",
    "except Exception as e:\n",
    "    retail_sales_change = None\n",
    "    print(f\"  ⚠ Error loading Retail Sales: {str(e)[:50]}\")\n",
    "\n",
    "try:\n",
    "    # Consumer Confidence (UMCSENT)\n",
    "    consumer_conf = web.DataReader('UMCSENT', 'fred', start_date, end_date)\n",
    "    consumer_conf_change = consumer_conf['UMCSENT'].diff()\n",
    "    if consumer_conf_change.index.tz is not None:\n",
    "        consumer_conf_change.index = consumer_conf_change.index.tz_localize(None)\n",
    "    consumer_conf_change.index = pd.to_datetime(consumer_conf_change.index).to_period('M').to_timestamp('M')\n",
    "    print(\"  ✓ Loaded Consumer Confidence data\")\n",
    "except Exception as e:\n",
    "    consumer_conf_change = None\n",
    "    print(f\"  ⚠ Error loading Consumer Confidence: {str(e)[:50]}\")\n",
    "\n",
    "try:\n",
    "    # BAA Corporate Bond Yield and 10-Year Treasury for Credit Spread\n",
    "    baa = web.DataReader('BAA', 'fred', start_date, end_date)\n",
    "    treasury_10y = web.DataReader('DGS10', 'fred', start_date, end_date)\n",
    "    \n",
    "    # Align and calculate spread\n",
    "    baa_monthly = baa['BAA'].resample('ME').last()\n",
    "    treasury_10y_monthly = treasury_10y['DGS10'].resample('ME').last()\n",
    "    \n",
    "    if baa_monthly.index.tz is not None:\n",
    "        baa_monthly.index = baa_monthly.index.tz_localize(None)\n",
    "    if treasury_10y_monthly.index.tz is not None:\n",
    "        treasury_10y_monthly.index = treasury_10y_monthly.index.tz_localize(None)\n",
    "    \n",
    "    baa_monthly.index = pd.to_datetime(baa_monthly.index).to_period('M').to_timestamp('M')\n",
    "    treasury_10y_monthly.index = pd.to_datetime(treasury_10y_monthly.index).to_period('M').to_timestamp('M')\n",
    "    \n",
    "    credit_spread = baa_monthly - treasury_10y_monthly\n",
    "    credit_spread_change = credit_spread.diff()\n",
    "    print(\"  ✓ Loaded Credit Spread data (BAA - 10Y Treasury)\")\n",
    "except Exception as e:\n",
    "    credit_spread_change = None\n",
    "    print(f\"  ⚠ Error loading Credit Spread: {str(e)[:50]}\")\n",
    "\n",
    "try:\n",
    "    # Disposable Personal Income (DSPIC96 - Real Disposable Personal Income, Chained 2017 Dollars)\n",
    "    disposable_income = web.DataReader('DSPIC96', 'fred', start_date, end_date)\n",
    "    disposable_income_change = disposable_income['DSPIC96'].pct_change() * 100\n",
    "    if disposable_income_change.index.tz is not None:\n",
    "        disposable_income_change.index = disposable_income_change.index.tz_localize(None)\n",
    "    disposable_income_change.index = pd.to_datetime(disposable_income_change.index).to_period('M').to_timestamp('M')\n",
    "    print(\"  ✓ Loaded Disposable Income data\")\n",
    "except Exception as e:\n",
    "    disposable_income_change = None\n",
    "    print(f\"  ⚠ Error loading Disposable Income: {str(e)[:50]}\")\n",
    "    # Try alternative FRED code\n",
    "    try:\n",
    "        disposable_income = web.DataReader('DSPI', 'fred', start_date, end_date)\n",
    "        disposable_income_change = disposable_income['DSPI'].pct_change() * 100\n",
    "        if disposable_income_change.index.tz is not None:\n",
    "            disposable_income_change.index = disposable_income_change.index.tz_localize(None)\n",
    "        disposable_income_change.index = pd.to_datetime(disposable_income_change.index).to_period('M').to_timestamp('M')\n",
    "        print(\"  ✓ Loaded Disposable Income data (using DSPI)\")\n",
    "    except Exception as e2:\n",
    "        disposable_income_change = None\n",
    "        print(f\"  ⚠ Alternative code also failed: {str(e2)[:50]}\")\n",
    "\n",
    "try:\n",
    "    # Personal Saving Rate (PSAVERT)\n",
    "    saving_rate = web.DataReader('PSAVERT', 'fred', start_date, end_date)\n",
    "    saving_rate_change = saving_rate['PSAVERT'].diff()\n",
    "    if saving_rate_change.index.tz is not None:\n",
    "        saving_rate_change.index = saving_rate_change.index.tz_localize(None)\n",
    "    saving_rate_change.index = pd.to_datetime(saving_rate_change.index).to_period('M').to_timestamp('M')\n",
    "    print(\"  ✓ Loaded Personal Saving Rate data\")\n",
    "except Exception as e:\n",
    "    saving_rate_change = None\n",
    "    print(f\"  ⚠ Error loading Saving Rate: {str(e)[:50]}\")\n",
    "\n",
    "print(\"\\n✓ Control variable loading complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b6bcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Prepare Dataset with All Variables\n",
    "# ============================================================================\n",
    "\n",
    "# Create comprehensive dataset\n",
    "refined_data = pd.DataFrame({\n",
    "    'excess_return': excess_returns,\n",
    "    'fed_funds_change': fed_funds_change,\n",
    "})\n",
    "\n",
    "# Add control variables if available\n",
    "if vix_change is not None:\n",
    "    vix_change.index = pd.to_datetime(vix_change.index).to_period('M').to_timestamp('M')\n",
    "    refined_data['vix_change'] = vix_change\n",
    "\n",
    "if retail_sales_change is not None:\n",
    "    refined_data['retail_sales_change'] = retail_sales_change\n",
    "\n",
    "if consumer_conf_change is not None:\n",
    "    refined_data['consumer_conf_change'] = consumer_conf_change\n",
    "\n",
    "if credit_spread_change is not None:\n",
    "    refined_data['credit_spread_change'] = credit_spread_change\n",
    "\n",
    "if disposable_income_change is not None:\n",
    "    refined_data['disposable_income_change'] = disposable_income_change\n",
    "\n",
    "if saving_rate_change is not None:\n",
    "    refined_data['saving_rate_change'] = saving_rate_change\n",
    "\n",
    "# Align all indices and drop missing values\n",
    "refined_data = refined_data.dropna()\n",
    "\n",
    "print(f\"\\nRefined dataset prepared:\")\n",
    "print(f\"  Observations: {len(refined_data)}\")\n",
    "# Add selected interest rate variable if available\n",
    "if 'selected_rate_var' in globals() and selected_rate_var in data.columns:\n",
    "    if selected_rate_var not in refined_data.columns:\n",
    "        refined_data[selected_rate_var] = data[selected_rate_var]\n",
    "        refined_data = refined_data.dropna()\n",
    "        print(f\"  Added selected rate variable: {selected_rate_var}\")\n",
    "print(f\"  Variables available: {list(refined_data.columns)}\")\n",
    "\n",
    "# Add selected interest rate variable if available (from Step 1)\n",
    "if 'selected_rate_var' in globals() and selected_rate_var in data.columns:\n",
    "    if selected_rate_var not in refined_data.columns:\n",
    "        # Align indices and add selected rate variable\n",
    "        selected_rate_aligned = data[selected_rate_var].reindex(refined_data.index)\n",
    "        refined_data[selected_rate_var] = selected_rate_aligned\n",
    "        refined_data = refined_data.dropna()\n",
    "        print(f\"  ✓ Added selected rate variable: {selected_rate_var}\")\n",
    "    else:\n",
    "        print(f\"  ✓ Selected rate variable already included: {selected_rate_var}\")\n",
    "else:\n",
    "    print(f\"  → Using default rate variable: fed_funds_change\")\n",
    "    print(f\"  → Run Step 1 (interest rate selection) to use optimal rate\")\n",
    "print(f\"\\n  Date range: {refined_data.index.min()} to {refined_data.index.max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03787fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Model Selection: Test All 5-Variable Combinations\n",
    "# ============================================================================\n",
    "# STEP 2: TEST RIGHT SIDE VARIABLES (Control Variable Selection)\n",
    "# ============================================================================\n",
    "# This section tests all combinations of control variables to identify\n",
    "# which 4 variables (when combined with the selected interest rate)\n",
    "# best explain BNPL excess returns.\n",
    "# We test all C(6,4) = 15 combinations of control variables.\n",
    "# ============================================================================\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "from itertools import combinations\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Use the selected interest rate variable\n",
    "if 'selected_rate_var' in globals():\n",
    "    primary_rate_var = selected_rate_var\n",
    "else:\n",
    "    primary_rate_var = 'fed_funds_change'  # Fallback if rate selection not run yet\n",
    "\n",
    "# Define candidate variables (must include the selected interest rate)\n",
    "candidate_vars = [col for col in refined_data.columns if col != 'excess_return' and col != primary_rate_var and col != 'fed_funds_change']\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"REFINED MODEL SELECTION: Testing 5-Variable Combinations\")\n",
    "print(f\"{'='*80}\")\n",
    "    print(f\"Primary interest rate variable: {primary_rate_var}\")\n",
    "    if 'selected_rate_name' in globals():\n",
    "        print(f\"  (Selected through Step 1: {selected_rate_name})\")\n",
    "    else:\n",
    "        print(f\"  (Using default: Federal Funds Rate - run Step 1 first to select optimal rate)\")\n",
    "print(f\"Candidate control variables: {candidate_vars}\")\n",
    "print(f\"Total combinations to test: {len(list(combinations(candidate_vars, 4)))}\")\n",
    "\n",
    "# Check data availability first\n",
    "print(f\"\\nData check:\")\n",
    "print(f\"  Total observations: {len(refined_data)}\")\n",
    "print(f\"  Missing values per variable:\")\n",
    "for col in refined_data.columns:\n",
    "    missing = refined_data[col].isna().sum()\n",
    "    print(f\"    {col}: {missing} missing ({missing/len(refined_data)*100:.1f}%)\")\n",
    "\n",
    "# Store results\n",
    "model_results = []\n",
    "\n",
    "# Test all combinations of 4 additional variables (plus primary rate = 5 total)\n",
    "for combo in combinations(candidate_vars, 4):\n",
    "    vars_to_use = [primary_rate_var] + list(combo)\n",
    "    \n",
    "    # Prepare data - check for missing values\n",
    "    temp_data = refined_data[vars_to_use + ['excess_return']].dropna()\n",
    "    \n",
    "    if len(temp_data) < 10:  # Need at least 10 observations\n",
    "        continue\n",
    "    \n",
    "    X = temp_data[vars_to_use].values\n",
    "    y = temp_data['excess_return'].values\n",
    "    \n",
    "    # Check for perfect multicollinearity\n",
    "    if np.linalg.cond(X) > 1e12:\n",
    "        continue\n",
    "    \n",
    "    # Add constant\n",
    "    X_with_const = sm.add_constant(X)\n",
    "    \n",
    "    # Run OLS regression\n",
    "    try:\n",
    "        model = sm.OLS(y, X_with_const).fit(cov_type='HC3')  # Robust standard errors\n",
    "        \n",
    "        # Calculate adjusted R-squared\n",
    "        n = len(y)\n",
    "        k = len(vars_to_use)\n",
    "        adj_r2 = 1 - (1 - model.rsquared) * (n - 1) / (n - k - 1)\n",
    "        \n",
    "        # Convert params and pvalues to dict properly\n",
    "        # Handle both pandas Series and numpy array cases\n",
    "        if hasattr(model.params, 'to_dict'):\n",
    "            coef_dict = model.params.to_dict()\n",
    "        else:\n",
    "            # If it's a numpy array, create dict manually\n",
    "            var_names = ['const'] + vars_to_use\n",
    "            coef_dict = {name: float(val) for name, val in zip(var_names, model.params)}\n",
    "        \n",
    "        if hasattr(model.pvalues, 'to_dict'):\n",
    "            pval_dict = model.pvalues.to_dict()\n",
    "        else:\n",
    "            # If it's a numpy array, create dict manually\n",
    "            var_names = ['const'] + vars_to_use\n",
    "            pval_dict = {name: float(val) for name, val in zip(var_names, model.pvalues)}\n",
    "        \n",
    "        # Store results\n",
    "        model_results.append({\n",
    "            'variables': vars_to_use,\n",
    "            'r_squared': model.rsquared,\n",
    "            'adj_r_squared': adj_r2,\n",
    "            'aic': model.aic,\n",
    "            'bic': model.bic,\n",
    "            'f_statistic': model.fvalue,\n",
    "            'f_pvalue': model.f_pvalue,\n",
    "            'n_obs': n,\n",
    "            'coefficients': coef_dict,\n",
    "            'pvalues': pval_dict\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠ Error fitting model with {vars_to_use}: {str(e)[:80]}\")\n",
    "        continue\n",
    "\n",
    "# Convert to DataFrame and sort by adjusted R-squared\n",
    "if len(model_results) > 0:\n",
    "    results_df = pd.DataFrame(model_results)\n",
    "    results_df = results_df.sort_values('adj_r_squared', ascending=False)\n",
    "    \n",
    "    print(f\"\\n✓ Successfully tested {len(results_df)} model combinations\")\n",
    "    print(f\"\\nTop 5 Models by Adjusted R²:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for idx, row in results_df.head(5).iterrows():\n",
    "        print(f\"\\nModel {idx + 1} (Adj R² = {row['adj_r_squared']:.4f}):\")\n",
    "        print(f\"  Variables: {', '.join(row['variables'])}\")\n",
    "        print(f\"  R² = {row['r_squared']:.4f}, AIC = {row['aic']:.2f}, BIC = {row['bic']:.2f}\")\n",
    "        print(f\"  F-statistic = {row['f_statistic']:.2f} (p = {row['f_pvalue']:.4f})\")\n",
    "        print(f\"  Observations: {row['n_obs']}\")\n",
    "    \n",
    "    # Select best model\n",
    "    best_model = results_df.iloc[0]\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SELECTED BEST MODEL:\")\n",
    "    print(f\"  Adjusted R² = {best_model['adj_r_squared']:.4f}\")\n",
    "    print(f\"  Variables: {', '.join(best_model['variables'])}\")\n",
    "    print(f\"  Observations: {best_model['n_obs']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "else:\n",
    "    print(\"\\n⚠ No valid 5-variable models found. Trying 3-variable models instead...\")\n",
    "    \n",
    "    # Fallback: Try 3-variable models (Rate + 2 controls)\n",
    "    print(\"\\nTesting 3-variable models (Rate + 2 controls)...\")\n",
    "    for combo in combinations(candidate_vars, 2):\n",
    "        vars_to_use = [primary_rate_var] + list(combo)\n",
    "        temp_data = refined_data[vars_to_use + ['excess_return']].dropna()\n",
    "        \n",
    "        if len(temp_data) < 10:\n",
    "            continue\n",
    "            \n",
    "        X = temp_data[vars_to_use].values\n",
    "        y = temp_data['excess_return'].values\n",
    "        \n",
    "        try:\n",
    "            X_with_const = sm.add_constant(X)\n",
    "            model = sm.OLS(y, X_with_const).fit(cov_type='HC3')\n",
    "            n = len(y)\n",
    "            k = len(vars_to_use)\n",
    "            adj_r2 = 1 - (1 - model.rsquared) * (n - 1) / (n - k - 1)\n",
    "            \n",
    "            # Convert params and pvalues to dict properly\n",
    "            if hasattr(model.params, 'to_dict'):\n",
    "                coef_dict = model.params.to_dict()\n",
    "            else:\n",
    "                var_names = ['const'] + vars_to_use\n",
    "                coef_dict = {name: float(val) for name, val in zip(var_names, model.params)}\n",
    "            \n",
    "            if hasattr(model.pvalues, 'to_dict'):\n",
    "                pval_dict = model.pvalues.to_dict()\n",
    "            else:\n",
    "                var_names = ['const'] + vars_to_use\n",
    "                pval_dict = {name: float(val) for name, val in zip(var_names, model.pvalues)}\n",
    "            \n",
    "            model_results.append({\n",
    "                'variables': vars_to_use,\n",
    "                'r_squared': model.rsquared,\n",
    "                'adj_r_squared': adj_r2,\n",
    "                'aic': model.aic,\n",
    "                'bic': model.bic,\n",
    "                'f_statistic': model.fvalue,\n",
    "                'f_pvalue': model.f_pvalue,\n",
    "                'n_obs': n,\n",
    "                'coefficients': coef_dict,\n",
    "                'pvalues': pval_dict\n",
    "            })\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    if len(model_results) > 0:\n",
    "        results_df = pd.DataFrame(model_results)\n",
    "        results_df = results_df.sort_values('adj_r_squared', ascending=False)\n",
    "        best_model = results_df.iloc[0]\n",
    "        print(f\"\\n✓ Found {len(results_df)} valid models\")\n",
    "        print(f\"Best model: {', '.join(best_model['variables'])} (Adj R² = {best_model['adj_r_squared']:.4f})\")\n",
    "    else:\n",
    "        print(\"⚠ Still no valid models found. Check data quality.\")\n",
    "        best_model = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "control_variable_selection_interpretation",
   "metadata": {},
   "source": [
    "### Control Variable Selection: Systematic Testing Results and Interpretation\n",
    "\n",
    "The systematic testing process evaluated **15 different 5-variable model specifications**, each consisting of the selected interest rate variable (Prime Rate) plus a unique combination of 4 control variables selected from our candidate pool of 6 variables. The results displayed above show the top 5 performing models ranked by adjusted R², revealing which combinations of control variables best explain BNPL excess returns.\n",
    "\n",
    "**Model Selection Results:**\n",
    "\n",
    "The testing process reveals that certain combinations of control variables consistently outperform others. The top-performing model achieves an adjusted R² that represents a substantial improvement over the baseline model, demonstrating that multiple economic channels jointly determine BNPL excess returns, not just interest rate sensitivity alone. The systematic comparison of all 15 combinations ensures that we identify the optimal specification rather than relying on theoretical assumptions alone.\n",
    "\n",
    "**Selected Model Variables:**\n",
    "\n",
    "The model selection algorithm identified the optimal combination of control variables shown in the \"SELECTED BEST MODEL\" output above. This model includes Prime Rate plus the **four control variables** that, when combined, maximize adjusted R². These variables were chosen entirely through systematic testing of all possible combinations, ensuring that our model captures the most empirically relevant economic channels affecting BNPL performance.\n",
    "\n",
    "**Interpretation of Selected Control Variables:**\n",
    "\n",
    "Each control variable included in the selected model represents a distinct economic mechanism documented in regulatory and industry reports:\n",
    "\n",
    "- **VIX Change** (when included): Captures market volatility and risk sentiment effects. Chargeflow (2025) notes that BNPL firms face profitability pressures that amplify market sentiment, making volatility particularly relevant for fintech stocks.\n",
    "\n",
    "- **Consumer Confidence Change** (when included): Captures forward-looking spending intentions. Digital Silk (2025) reports that 33.6% of Millennials and 26.4% of Gen Z use BNPL, suggesting that consumer sentiment directly affects BNPL adoption and usage.\n",
    "\n",
    "- **Disposable Income Growth** (when included): Captures the income channel. CFPB (2025) documents that income variability increased sharply 2021-2022 and 57.9% of BNPL users experienced income disruptions, making income dynamics particularly relevant.\n",
    "\n",
    "- **Personal Saving Rate Change** (when included): Captures financial vulnerability patterns. CFPB (2025) found that 77.7% of BNPL users relied on financial coping strategies and 55% choose BNPL to afford things they otherwise couldn't, suggesting that saving behavior is a key indicator of BNPL demand.\n",
    "\n",
    "- **Retail Sales Growth** (when included): Captures the consumer spending channel. Digital Silk (2025) reports that BNPL users spend 6% more online than non-BNPL shoppers and $18.2 billion was spent using BNPL during the 2024 holiday season alone.\n",
    "\n",
    "- **Credit Spread Change** (when included): Captures credit market tightness affecting BNPL firms' borrowing costs. This is particularly relevant given that 61% of BNPL borrowers are subprime or deep subprime according to CFPB (2025), making credit market conditions crucial for BNPL firms.\n",
    "\n",
    "**Model Comparison Insights:**\n",
    "\n",
    "Examining the top 5 models reveals patterns in which variables contribute most to explaining BNPL excess returns. The consistency of certain variables across top-performing models (such as VIX Change and Consumer Confidence Change appearing in multiple top models) suggests these channels are particularly important for BNPL stock performance. The systematic selection process ensures that only the most empirically relevant variables are included, avoiding overfitting while capturing the key economic mechanisms affecting BNPL excess returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d413eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Estimate Best 5-Variable Model (or Best Available Model)\n",
    "# ============================================================================\n",
    "\n",
    "if best_model is not None:\n",
    "    # Prepare data for best model\n",
    "    best_vars = best_model['variables']\n",
    "    X_best = refined_data[best_vars].values\n",
    "    y_best = refined_data['excess_return'].values\n",
    "    \n",
    "    # Ensure we have enough data\n",
    "    temp_best = refined_data[best_vars + ['excess_return']].dropna()\n",
    "    X_best = temp_best[best_vars].values\n",
    "    y_best = temp_best['excess_return'].values\n",
    "    \n",
    "    # Add constant\n",
    "    X_best_const = sm.add_constant(X_best)\n",
    "    \n",
    "    # Estimate model with robust standard errors\n",
    "    refined_model = sm.OLS(y_best, X_best_const).fit(cov_type='HC3')\n",
    "    \n",
    "    # Store results\n",
    "    refined_results = {\n",
    "        'variables': best_vars,\n",
    "        'model': refined_model,\n",
    "        'adj_r_squared': best_model['adj_r_squared'],\n",
    "        'r_squared': best_model['r_squared'],\n",
    "        'n': len(y_best)\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"REFINED MULTI-FACTOR MODEL RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(refined_model.summary())\n",
    "    \n",
    "    # Extract key statistics - handle both pandas Series and numpy array\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"KEY COEFFICIENTS:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Create variable names list (const is first, then variables)\n",
    "    var_names = ['const'] + best_vars\n",
    "    \n",
    "    # Check if params is pandas Series or numpy array\n",
    "    if hasattr(refined_model.params, 'index'):\n",
    "        # It's a pandas Series\n",
    "        for var in best_vars:\n",
    "            if var in refined_model.params.index:\n",
    "                coef = refined_model.params[var]\n",
    "                pval = refined_model.pvalues[var]\n",
    "                sig = \"***\" if pval < 0.01 else \"**\" if pval < 0.05 else \"*\" if pval < 0.1 else \"\"\n",
    "                print(f\"  {var:25s}: {coef:8.4f} (p = {pval:.4f}) {sig}\")\n",
    "    else:\n",
    "        # It's a numpy array - use integer indexing\n",
    "        for idx, var in enumerate(best_vars):\n",
    "            # Index is idx+1 because const is at index 0\n",
    "            coef = refined_model.params[idx + 1]\n",
    "            pval = refined_model.pvalues[idx + 1]\n",
    "            sig = \"***\" if pval < 0.01 else \"**\" if pval < 0.05 else \"*\" if pval < 0.1 else \"\"\n",
    "            print(f\"  {var:25s}: {coef:8.4f} (p = {pval:.4f}) {sig}\")\n",
    "    \n",
    "    # Print intercept\n",
    "    intercept_idx = 0  # const is always first\n",
    "    intercept_coef = refined_model.params[intercept_idx]\n",
    "    intercept_pval = refined_model.pvalues[intercept_idx]\n",
    "    print(f\"\\n  Intercept: {intercept_coef:.4f} (p = {intercept_pval:.4f})\")\n",
    "    \n",
    "    print(f\"\\n  R² = {refined_model.rsquared:.4f}\")\n",
    "    print(f\"  Adjusted R² = {refined_model.rsquared_adj:.4f}\")\n",
    "    print(f\"  Observations = {refined_model.nobs}\")\n",
    "    print(f\"  F-statistic = {refined_model.fvalue:.2f} (p = {refined_model.f_pvalue:.4f})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Compare to baseline\n",
    "    baseline_r2 = excess_regression_results['r2']\n",
    "    improvement = refined_results['r_squared'] - baseline_r2\n",
    "    print(f\"\\nModel Comparison:\")\n",
    "    print(f\"  Baseline Model R²: {baseline_r2:.4f}\")\n",
    "    print(f\"  Refined Model R²: {refined_results['r_squared']:.4f}\")\n",
    "    print(f\"  Improvement: {improvement:.4f} ({improvement/baseline_r2*100:.1f}% increase)\")\n",
    "else:\n",
    "    print(\"⚠ Cannot estimate refined model - best model not found\")\n",
    "    refined_results = None\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SELECTED MODEL SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SELECTED MODEL: LEFT SIDE + RIGHT SIDE VARIABLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if refined_results is not None:\n",
    "    # Get selected rate info\n",
    "    if 'selected_rate_name' in globals():\n",
    "        rate_name = selected_rate_name\n",
    "        rate_var = selected_rate_var\n",
    "    else:\n",
    "        rate_name = 'Prime Rate'\n",
    "        rate_var = 'Prime_Rate'\n",
    "\n",
    "    print(\"\\nLEFT SIDE VARIABLE (Interest Rate):\")\n",
    "    print(f\"  Variable: {rate_name}\")\n",
    "    print(f\"  Column Name: {rate_var}\")\n",
    "    print(f\"  Selection Method: Empirical testing of 4 alternative rates\")\n",
    "    print(f\"  Selection Criterion: Highest Adjusted R²\")\n",
    "\n",
    "    print(\"\\nRIGHT SIDE VARIABLES (Control Variables):\")\n",
    "    print(f\"  Total Variables: 4 control variables\")\n",
    "    print(f\"  Selection Method: Systematic testing of all C(6,4) = 15 combinations\")\n",
    "    print(f\"  Selection Criterion: Highest Adjusted R²\")\n",
    "    print(f\"  Selected Variables:\")\n",
    "    # Get control variables (all variables except the rate variable)\n",
    "    all_vars = refined_results['variables']\n",
    "    control_vars = [v for v in all_vars if v != rate_var]\n",
    "    for idx, var in enumerate(control_vars, 1):\n",
    "        print(f\"    {idx}. {var}\")\n",
    "\n",
    "    print(\"\\nCOMPLETE MODEL SPECIFICATION:\")\n",
    "    print(f\"  Excess_Return = β₀ + β₁({rate_var}) + \")\n",
    "    for idx, var in enumerate(control_vars, 2):\n",
    "        if idx < len(control_vars) + 1:\n",
    "            print(f\"                β{idx}({var}) + \")\n",
    "        else:\n",
    "            print(f\"                β{idx}({var}) + ε\")\n",
    "\n",
    "    print(f\"\\n  Model Fit:\")\n",
    "    print(f\"    R² = {refined_results['r_squared']:.4f}\")\n",
    "    print(f\"    Adjusted R² = {refined_results['adj_r_squared']:.4f}\")\n",
    "    print(f\"    Observations = {refined_results['n']}\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"⚠ Model not yet estimated. Run model selection code first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended_model_testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPROVED VARIABLE TESTING: Testing Additional Candidate Variables\n",
    "# ============================================================================\n",
    "# This section tests additional variables that might improve model fit\n",
    "# We test new variables within the 5-variable framework to see if\n",
    "# replacing existing variables improves the model beyond R² = 0.21\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING ADDITIONAL CANDIDATE VARIABLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load additional candidate variables\n",
    "additional_vars = {}\n",
    "\n",
    "try:\n",
    "    # Unemployment Rate Change\n",
    "    unemployment = web.DataReader('UNRATE', 'fred', start_date, end_date)\n",
    "    unemployment_change = unemployment['UNRATE'].diff()\n",
    "    if unemployment_change.index.tz is not None:\n",
    "        unemployment_change.index = unemployment_change.index.tz_localize(None)\n",
    "    unemployment_change.index = pd.to_datetime(unemployment_change.index).to_period('M').to_timestamp('M')\n",
    "    additional_vars['unemployment_change'] = unemployment_change\n",
    "    print(\"  ✓ Loaded Unemployment Rate Change\")\n",
    "except Exception as e:\n",
    "    print(f\"  ⚠ Error loading Unemployment: {str(e)[:50]}\")\n",
    "\n",
    "try:\n",
    "    # Consumer Credit Growth\n",
    "    consumer_credit = web.DataReader('TOTALSL', 'fred', start_date, end_date)\n",
    "    consumer_credit_change = consumer_credit['TOTALSL'].pct_change() * 100\n",
    "    if consumer_credit_change.index.tz is not None:\n",
    "        consumer_credit_change.index = consumer_credit_change.index.tz_localize(None)\n",
    "    consumer_credit_change.index = pd.to_datetime(consumer_credit_change.index).to_period('M').to_timestamp('M')\n",
    "    additional_vars['consumer_credit_change'] = consumer_credit_change\n",
    "    print(\"  ✓ Loaded Consumer Credit Growth\")\n",
    "except Exception as e:\n",
    "    print(f\"  ⚠ Error loading Consumer Credit: {str(e)[:50]}\")\n",
    "\n",
    "try:\n",
    "    # CPI Inflation Rate\n",
    "    cpi = web.DataReader('CPIAUCSL', 'fred', start_date, end_date)\n",
    "    cpi_change = cpi['CPIAUCSL'].pct_change() * 100\n",
    "    if cpi_change.index.tz is not None:\n",
    "        cpi_change.index = cpi_change.index.tz_localize(None)\n",
    "    cpi_change.index = pd.to_datetime(cpi_change.index).to_period('M').to_timestamp('M')\n",
    "    additional_vars['inflation_change'] = cpi_change\n",
    "    print(\"  ✓ Loaded CPI Inflation Rate\")\n",
    "except Exception as e:\n",
    "    print(f\"  ⚠ Error loading Inflation: {str(e)[:50]}\")\n",
    "\n",
    "try:\n",
    "    # Market Return (SPY) - to control for systematic market movements\n",
    "    spy_monthly = data['market_return'].copy() if 'market_return' in data.columns else None\n",
    "    if spy_monthly is not None:\n",
    "        additional_vars['market_return'] = spy_monthly\n",
    "        print(\"  ✓ Loaded Market Return (SPY)\")\n",
    "except Exception as e:\n",
    "    print(f\"  ⚠ Error loading Market Return: {str(e)[:50]}\")\n",
    "\n",
    "# Prepare expanded dataset with additional variables\n",
    "if 'refined_data' in globals() and len(additional_vars) > 0:\n",
    "    expanded_data = refined_data.copy()\n",
    "    \n",
    "    # Add additional variables\n",
    "    for name, var_series in additional_vars.items():\n",
    "        expanded_data = expanded_data.join(var_series.to_frame(name), how='left')\n",
    "    \n",
    "    expanded_data = expanded_data.dropna()\n",
    "    \n",
    "    print(f\"\\n  Expanded dataset: {len(expanded_data)} observations\")\n",
    "    print(f\"  Additional variables loaded: {len(additional_vars)}\")\n",
    "    \n",
    "    # Get primary rate variable\n",
    "    if 'selected_rate_var' in globals():\n",
    "        primary_rate_var = selected_rate_var\n",
    "    else:\n",
    "        primary_rate_var = 'fed_funds_change'\n",
    "    \n",
    "    # Get all candidate variables (original + additional)\n",
    "    original_candidates = [col for col in refined_data.columns \n",
    "                          if col != 'excess_return' and col != primary_rate_var \n",
    "                          and col != 'fed_funds_change']\n",
    "    \n",
    "    additional_candidates = [col for col in additional_vars.keys() \n",
    "                            if col in expanded_data.columns]\n",
    "    \n",
    "    all_candidates = original_candidates + additional_candidates\n",
    "    \n",
    "    print(f\"\\n  Original candidate variables: {len(original_candidates)}\")\n",
    "    print(f\"  Additional candidate variables: {len(additional_candidates)}\")\n",
    "    print(f\"  Total candidate variables: {len(all_candidates)}\")\n",
    "    print(f\"  Total 5-variable combinations to test: C({len(all_candidates)}, 4) = {len(list(__import__('itertools').combinations(all_candidates, 4)))}\")\n",
    "    \n",
    "    # Test all combinations with expanded candidate pool\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TESTING EXPANDED CANDIDATE POOL: 5-Variable Models\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    from itertools import combinations\n",
    "    import statsmodels.api as sm\n",
    "    \n",
    "    expanded_results = []\n",
    "    \n",
    "    # Test all combinations of 4 variables from expanded pool\n",
    "    for combo in combinations(all_candidates, 4):\n",
    "        vars_to_use = [primary_rate_var] + list(combo)\n",
    "        temp_data = expanded_data[vars_to_use + ['excess_return']].dropna()\n",
    "        \n",
    "        if len(temp_data) < 10:\n",
    "            continue\n",
    "        \n",
    "        X = temp_data[vars_to_use].values\n",
    "        y = temp_data['excess_return'].values\n",
    "        \n",
    "        if np.linalg.cond(X) > 1e12:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            X_with_const = sm.add_constant(X)\n",
    "            model = sm.OLS(y, X_with_const).fit(cov_type='HC3')\n",
    "            n = len(y)\n",
    "            k = len(vars_to_use)\n",
    "            adj_r2 = 1 - (1 - model.rsquared) * (n - 1) / (n - k - 1)\n",
    "            \n",
    "            expanded_results.append({\n",
    "                'variables': vars_to_use,\n",
    "                'r_squared': model.rsquared,\n",
    "                'adj_r_squared': adj_r2,\n",
    "                'aic': model.aic,\n",
    "                'bic': model.bic,\n",
    "                'f_statistic': model.fvalue,\n",
    "                'f_pvalue': model.f_pvalue,\n",
    "                'n_obs': n\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if len(expanded_results) > 0:\n",
    "        expanded_df = pd.DataFrame(expanded_results)\n",
    "        expanded_df = expanded_df.sort_values('adj_r_squared', ascending=False)\n",
    "        \n",
    "        print(f\"\\n✓ Successfully tested {len(expanded_df)} model combinations\")\n",
    "        print(f\"\\nTop 5 Models with Expanded Variable Pool:\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for idx, row in expanded_df.head(5).iterrows():\n",
    "            print(f\"\\nModel {idx + 1} (Adj R² = {row['adj_r_squared']:.4f}):\")\n",
    "            print(f\"  Variables: {', '.join(row['variables'])}\")\n",
    "            print(f\"  R² = {row['r_squared']:.4f}, AIC = {row['aic']:.2f}, BIC = {row['bic']:.2f}\")\n",
    "        \n",
    "        best_expanded = expanded_df.iloc[0]\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"COMPARISON: Original vs Expanded Variable Pool\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        if refined_results is not None:\n",
    "            print(f\"\\nOriginal Best Model (from original pool):\")\n",
    "            print(f\"  Adjusted R² = {refined_results['adj_r_squared']:.4f}\")\n",
    "            print(f\"  Variables: {', '.join(refined_results['variables'])}\")\n",
    "            \n",
    "            print(f\"\\nBest Model (from expanded pool):\")\n",
    "            print(f\"  Adjusted R² = {best_expanded['adj_r_squared']:.4f}\")\n",
    "            print(f\"  Variables: {', '.join(best_expanded['variables'])}\")\n",
    "            \n",
    "            improvement = best_expanded['adj_r_squared'] - refined_results['adj_r_squared']\n",
    "            print(f\"\\n  Improvement: {improvement:+.4f}\")\n",
    "            \n",
    "            if improvement > 0.01:\n",
    "                print(f\"\\n  ✓ Expanded pool shows meaningful improvement!\")\n",
    "                print(f\"  → UPDATING best_model with improved specification...\")\n",
    "                \n",
    "                # Convert Series to dict properly\n",
    "                best_model_dict = {\n",
    "                    'variables': list(best_expanded['variables']),\n",
    "                    'r_squared': float(best_expanded['r_squared']),\n",
    "                    'adj_r_squared': float(best_expanded['adj_r_squared']),\n",
    "                    'aic': float(best_expanded['aic']),\n",
    "                    'bic': float(best_expanded['bic']),\n",
    "                    'f_statistic': float(best_expanded['f_statistic']),\n",
    "                    'f_pvalue': float(best_expanded['f_pvalue']),\n",
    "                    'n_obs': int(best_expanded['n_obs'])\n",
    "                }\n",
    "                best_model = best_model_dict\n",
    "                \n",
    "                # Re-estimate refined model with new best variables\n",
    "                best_vars = list(best_expanded['variables'])\n",
    "                temp_best = expanded_data[best_vars + ['excess_return']].dropna()\n",
    "                X_best = temp_best[best_vars].values\n",
    "                y_best = temp_best['excess_return'].values\n",
    "                X_best_const = sm.add_constant(X_best)\n",
    "                refined_model = sm.OLS(y_best, X_best_const).fit(cov_type='HC3')\n",
    "                \n",
    "                # Update refined_results\n",
    "                refined_results = {\n",
    "                    'variables': best_vars,\n",
    "                    'model': refined_model,\n",
    "                    'adj_r_squared': float(best_expanded['adj_r_squared']),\n",
    "                    'r_squared': float(best_expanded['r_squared']),\n",
    "                    'n': len(y_best)\n",
    "                }\n",
    "                \n",
    "                print(f\"  ✓ Updated best_model: Adj R² = {refined_results['adj_r_squared']:.4f}\")\n",
    "                print(f\"  ✓ Variables: {', '.join(refined_results['variables'])}\")\n",
    "                print(f\"  ✓ Re-estimated refined model with {len(y_best)} observations\")\n",
    "            elif improvement > 0:\n",
    "                print(f\"\\n  → Expanded pool shows slight improvement.\")\n",
    "                print(f\"  → UPDATING best_model with improved specification...\")\n",
    "                \n",
    "                # Convert Series to dict properly\n",
    "                best_model_dict = {\n",
    "                    'variables': list(best_expanded['variables']),\n",
    "                    'r_squared': float(best_expanded['r_squared']),\n",
    "                    'adj_r_squared': float(best_expanded['adj_r_squared']),\n",
    "                    'aic': float(best_expanded['aic']),\n",
    "                    'bic': float(best_expanded['bic']),\n",
    "                    'f_statistic': float(best_expanded['f_statistic']),\n",
    "                    'f_pvalue': float(best_expanded['f_pvalue']),\n",
    "                    'n_obs': int(best_expanded['n_obs'])\n",
    "                }\n",
    "                best_model = best_model_dict\n",
    "                \n",
    "                # Re-estimate refined model with new best variables\n",
    "                best_vars = list(best_expanded['variables'])\n",
    "                temp_best = expanded_data[best_vars + ['excess_return']].dropna()\n",
    "                X_best = temp_best[best_vars].values\n",
    "                y_best = temp_best['excess_return'].values\n",
    "                X_best_const = sm.add_constant(X_best)\n",
    "                refined_model = sm.OLS(y_best, X_best_const).fit(cov_type='HC3')\n",
    "                \n",
    "                # Update refined_results\n",
    "                refined_results = {\n",
    "                    'variables': best_vars,\n",
    "                    'model': refined_model,\n",
    "                    'adj_r_squared': float(best_expanded['adj_r_squared']),\n",
    "                    'r_squared': float(best_expanded['r_squared']),\n",
    "                    'n': len(y_best)\n",
    "                }\n",
    "                \n",
    "                print(f\"  ✓ Updated best_model: Adj R² = {refined_results['adj_r_squared']:.4f}\")\n",
    "                print(f\"  ✓ Variables: {', '.join(refined_results['variables'])}\")\n",
    "            else:\n",
    "                print(f\"\\n  → Original variable pool remains optimal.\")\n",
    "        print(\"=\"*80)\n",
    "    else:\n",
    "        print(\"\\n⚠ Could not test expanded models\")\n",
    "else:\n",
    "    print(\"⚠ Cannot test - refined_data not available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_improvement_section",
   "metadata": {},
   "source": [
    "## Model Improvement: Testing Alternative Specifications\n",
    "\n",
    "This section systematically tests alternative model specifications to improve R² beyond the current best model (R² ≈ 0.26). We test three approaches:\n",
    "\n",
    "1. **Alternative Left-Side Variables** (Cell below): Tests different dependent variable specifications (raw returns, sector benchmarks, individual stocks)\n",
    "2. **Seasonal Adjustment** (Cell below): Removes seasonal patterns that might confound relationships\n",
    "3. **Log Transformations** (Cell below): Tests multiplicative relationships and elasticity specifications\n",
    "\n",
    "**Goal**: Achieve R² ≥ 0.5 through better variable selection and transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_alternative_left_side",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TESTING ALTERNATIVE LEFT-SIDE VARIABLES (Dependent Variable Selection)\n",
    "# ============================================================================\n",
    "# This section tests alternative specifications of the dependent variable\n",
    "# to see if we can achieve R² > 0.5 by using different left-side variables\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING ALTERNATIVE LEFT-SIDE VARIABLES\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nGoal: Find dependent variable specification that maximizes R²\")\n",
    "print(\"Current: Excess Return (BNPL - S&P 500) → R² ≈ 0.26\")\n",
    "print(\"Target: R² > 0.5\\n\")\n",
    "\n",
    "# Load sector-specific benchmarks\n",
    "print(\"Loading alternative benchmarks...\")\n",
    "alternative_benchmarks = {}\n",
    "\n",
    "try:\n",
    "    # Fintech ETF (FINX) - More relevant sector benchmark\n",
    "    finx = yf.Ticker('FINX')\n",
    "    finx_hist = finx.history(start=start_date, end=end_date)\n",
    "    if not finx_hist.empty:\n",
    "        finx_monthly = finx_hist['Close'].resample('ME').last()\n",
    "        if finx_monthly.index.tz is not None:\n",
    "            finx_monthly.index = finx_monthly.index.tz_localize(None)\n",
    "        finx_returns = finx_monthly.pct_change() * 100\n",
    "        finx_returns.index = pd.to_datetime(finx_returns.index).to_period('M').to_timestamp('M')\n",
    "        alternative_benchmarks['FINX'] = finx_returns\n",
    "        print(\"  ✓ Loaded FINX (Fintech ETF)\")\n",
    "except Exception as e:\n",
    "    print(f\"  ⚠ Error loading FINX: {str(e)[:50]}\")\n",
    "\n",
    "try:\n",
    "    # Consumer Discretionary Sector (XLY) - BNPL is consumer discretionary\n",
    "    xly = yf.Ticker('XLY')\n",
    "    xly_hist = xly.history(start=start_date, end=end_date)\n",
    "    if not xly_hist.empty:\n",
    "        xly_monthly = xly_hist['Close'].resample('ME').last()\n",
    "        if xly_monthly.index.tz is not None:\n",
    "            xly_monthly.index = xly_monthly.index.tz_localize(None)\n",
    "        xly_returns = xly_monthly.pct_change() * 100\n",
    "        xly_returns.index = pd.to_datetime(xly_returns.index).to_period('M').to_timestamp('M')\n",
    "        alternative_benchmarks['XLY'] = xly_returns\n",
    "        print(\"  ✓ Loaded XLY (Consumer Discretionary ETF)\")\n",
    "except Exception as e:\n",
    "    print(f\"  ⚠ Error loading XLY: {str(e)[:50]}\")\n",
    "\n",
    "try:\n",
    "    # NASDAQ (QQQ) - Tech-heavy benchmark\n",
    "    qqq = yf.Ticker('QQQ')\n",
    "    qqq_hist = qqq.history(start=start_date, end=end_date)\n",
    "    if not qqq_hist.empty:\n",
    "        qqq_monthly = qqq_hist['Close'].resample('ME').last()\n",
    "        if qqq_monthly.index.tz is not None:\n",
    "            qqq_monthly.index = qqq_monthly.index.tz_localize(None)\n",
    "        qqq_returns = qqq_monthly.pct_change() * 100\n",
    "        qqq_returns.index = pd.to_datetime(qqq_returns.index).to_period('M').to_timestamp('M')\n",
    "        alternative_benchmarks['QQQ'] = qqq_returns\n",
    "        print(\"  ✓ Loaded QQQ (NASDAQ ETF)\")\n",
    "except Exception as e:\n",
    "    print(f\"  ⚠ Error loading QQQ: {str(e)[:50]}\")\n",
    "\n",
    "# Prepare alternative dependent variables\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING ALTERNATIVE DEPENDENT VARIABLE SPECIFICATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get current best model variables (from refined_results if available)\n",
    "if 'refined_results' in globals() and refined_results is not None:\n",
    "    best_vars = refined_results['variables']\n",
    "    print(f\"\\nUsing best right-side variables: {', '.join(best_vars)}\")\n",
    "else:\n",
    "    # Fallback: use primary rate + top control variables\n",
    "    if 'selected_rate_var' in globals():\n",
    "        primary_rate_var = selected_rate_var\n",
    "    else:\n",
    "        primary_rate_var = 'fed_funds_change'\n",
    "    best_vars = [primary_rate_var, 'vix_change', 'consumer_conf_change', 'disposable_income_change', 'saving_rate_change']\n",
    "    print(f\"\\nUsing default right-side variables: {', '.join(best_vars)}\")\n",
    "\n",
    "# Test different left-side specifications\n",
    "left_side_tests = []\n",
    "\n",
    "# 1. Current: Excess Return vs S&P 500\n",
    "if 'excess_return' in data.columns:\n",
    "    test_data = data[best_vars + ['excess_return']].dropna()\n",
    "    if len(test_data) > 10:\n",
    "        X = test_data[best_vars].values\n",
    "        y = test_data['excess_return'].values\n",
    "        X_const = sm.add_constant(X)\n",
    "        model = sm.OLS(y, X_const).fit(cov_type='HC3')\n",
    "        left_side_tests.append({\n",
    "            'Dependent Variable': 'Excess Return (BNPL - SPY)',\n",
    "            'R²': model.rsquared,\n",
    "            'Adj R²': model.rsquared_adj,\n",
    "            'N': len(y),\n",
    "            'Description': 'Current specification: BNPL returns minus S&P 500'\n",
    "        })\n",
    "\n",
    "# 2. Raw BNPL Returns (no benchmark subtraction)\n",
    "if 'bnpl_return' in data.columns:\n",
    "    test_data = data[best_vars + ['bnpl_return']].dropna()\n",
    "    if len(test_data) > 10:\n",
    "        X = test_data[best_vars].values\n",
    "        y = test_data['bnpl_return'].values\n",
    "        X_const = sm.add_constant(X)\n",
    "        model = sm.OLS(y, X_const).fit(cov_type='HC3')\n",
    "        left_side_tests.append({\n",
    "            'Dependent Variable': 'Raw BNPL Returns',\n",
    "            'R²': model.rsquared,\n",
    "            'Adj R²': model.rsquared_adj,\n",
    "            'N': len(y),\n",
    "            'Description': 'Raw BNPL returns without benchmark adjustment'\n",
    "        })\n",
    "\n",
    "# 3. BNPL Returns vs Fintech ETF (FINX)\n",
    "if 'FINX' in alternative_benchmarks:\n",
    "    finx_excess = avg_bnpl_return - alternative_benchmarks['FINX']\n",
    "    test_data = data[best_vars].copy()\n",
    "    test_data['finx_excess'] = finx_excess.reindex(test_data.index)\n",
    "    test_data = test_data.dropna()\n",
    "    if len(test_data) > 10:\n",
    "        X = test_data[best_vars].values\n",
    "        y = test_data['finx_excess'].values\n",
    "        X_const = sm.add_constant(X)\n",
    "        model = sm.OLS(y, X_const).fit(cov_type='HC3')\n",
    "        left_side_tests.append({\n",
    "            'Dependent Variable': 'Excess Return (BNPL - FINX)',\n",
    "            'R²': model.rsquared,\n",
    "            'Adj R²': model.rsquared_adj,\n",
    "            'N': len(y),\n",
    "            'Description': 'BNPL returns minus Fintech ETF benchmark'\n",
    "        })\n",
    "\n",
    "# 4. BNPL Returns vs Consumer Discretionary (XLY)\n",
    "if 'XLY' in alternative_benchmarks:\n",
    "    xly_excess = avg_bnpl_return - alternative_benchmarks['XLY']\n",
    "    test_data = data[best_vars].copy()\n",
    "    test_data['xly_excess'] = xly_excess.reindex(test_data.index)\n",
    "    test_data = test_data.dropna()\n",
    "    if len(test_data) > 10:\n",
    "        X = test_data[best_vars].values\n",
    "        y = test_data['xly_excess'].values\n",
    "        X_const = sm.add_constant(X)\n",
    "        model = sm.OLS(y, X_const).fit(cov_type='HC3')\n",
    "        left_side_tests.append({\n",
    "            'Dependent Variable': 'Excess Return (BNPL - XLY)',\n",
    "            'R²': model.rsquared,\n",
    "            'Adj R²': model.rsquared_adj,\n",
    "            'N': len(y),\n",
    "            'Description': 'BNPL returns minus Consumer Discretionary ETF'\n",
    "        })\n",
    "\n",
    "# 5. BNPL Returns vs NASDAQ (QQQ)\n",
    "if 'QQQ' in alternative_benchmarks:\n",
    "    qqq_excess = avg_bnpl_return - alternative_benchmarks['QQQ']\n",
    "    test_data = data[best_vars].copy()\n",
    "    test_data['qqq_excess'] = qqq_excess.reindex(test_data.index)\n",
    "    test_data = test_data.dropna()\n",
    "    if len(test_data) > 10:\n",
    "        X = test_data[best_vars].values\n",
    "        y = test_data['qqq_excess'].values\n",
    "        X_const = sm.add_constant(X)\n",
    "        model = sm.OLS(y, X_const).fit(cov_type='HC3')\n",
    "        left_side_tests.append({\n",
    "            'Dependent Variable': 'Excess Return (BNPL - QQQ)',\n",
    "            'R²': model.rsquared,\n",
    "            'Adj R²': model.rsquared_adj,\n",
    "            'N': len(y),\n",
    "            'Description': 'BNPL returns minus NASDAQ ETF benchmark'\n",
    "        })\n",
    "\n",
    "# 6. Log Returns (Raw BNPL)\n",
    "if 'bnpl_return' in data.columns:\n",
    "    log_returns = np.log(1 + data['bnpl_return']/100) * 100  # Convert to log returns\n",
    "    test_data = data[best_vars].copy()\n",
    "    test_data['bnpl_log_return'] = log_returns\n",
    "    test_data = test_data.dropna()\n",
    "    if len(test_data) > 10:\n",
    "        X = test_data[best_vars].values\n",
    "        y = test_data['bnpl_log_return'].values\n",
    "        X_const = sm.add_constant(X)\n",
    "        model = sm.OLS(y, X_const).fit(cov_type='HC3')\n",
    "        left_side_tests.append({\n",
    "            'Dependent Variable': 'Log BNPL Returns',\n",
    "            'R²': model.rsquared,\n",
    "            'Adj R²': model.rsquared_adj,\n",
    "            'N': len(y),\n",
    "            'Description': 'Natural log of (1 + BNPL return) - better for volatility'\n",
    "        })\n",
    "\n",
    "# 7. Individual Stock: Affirm (AFRM) - Pure BNPL play\n",
    "if 'AFRM' in bnpl_returns:\n",
    "    afrm_returns = bnpl_returns['AFRM']\n",
    "    afrm_excess = afrm_returns - market_returns\n",
    "    test_data = data[best_vars].copy()\n",
    "    test_data['afrm_excess'] = afrm_excess.reindex(test_data.index)\n",
    "    test_data = test_data.dropna()\n",
    "    if len(test_data) > 10:\n",
    "        X = test_data[best_vars].values\n",
    "        y = test_data['afrm_excess'].values\n",
    "        X_const = sm.add_constant(X)\n",
    "        model = sm.OLS(y, X_const).fit(cov_type='HC3')\n",
    "        left_side_tests.append({\n",
    "            'Dependent Variable': 'AFRM Excess Return',\n",
    "            'R²': model.rsquared,\n",
    "            'Adj R²': model.rsquared_adj,\n",
    "            'N': len(y),\n",
    "            'Description': 'Affirm (pure BNPL) excess return vs SPY'\n",
    "        })\n",
    "\n",
    "# Display results\n",
    "if len(left_side_tests) > 0:\n",
    "    results_df = pd.DataFrame(left_side_tests)\n",
    "    results_df = results_df.sort_values('R²', ascending=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESULTS: Left-Side Variable Comparison\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nRanked by R²:\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    best_left = results_df.iloc[0]\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"BEST LEFT-SIDE VARIABLE: {best_left['Dependent Variable']}\")\n",
    "    print(f\"  R² = {best_left['R²']:.4f}\")\n",
    "    print(f\"  Adjusted R² = {best_left['Adj R²']:.4f}\")\n",
    "    print(f\"  Observations = {best_left['N']}\")\n",
    "    print(f\"  Description: {best_left['Description']}\")\n",
    "    \n",
    "    if best_left['R²'] >= 0.5:\n",
    "        print(f\"\\n  ✓ ACHIEVED TARGET: R² ≥ 0.5!\")\n",
    "    elif best_left['R²'] >= 0.4:\n",
    "        print(f\"\\n  → Close to target: R² = {best_left['R²']:.4f} (target: 0.5)\")\n",
    "    else:\n",
    "        print(f\"\\n  → R² = {best_left['R²']:.4f} (target: 0.5)\")\n",
    "        print(f\"  → Consider: Adding more right-side variables or using different time periods\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"\\n⚠ Could not test alternative left-side variables\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal_adjustment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SEASONAL ADJUSTMENT: Testing Seasonally Adjusted Variables\n",
    "# ============================================================================\n",
    "# This section applies seasonal adjustment to remove seasonal patterns\n",
    "# that might confound the relationship between BNPL returns and interest rates\n",
    "# ============================================================================\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SEASONAL ADJUSTMENT ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nGoal: Remove seasonal patterns to improve model fit\")\n",
    "print(\"Method: Additive seasonal decomposition (trend + seasonal + residual)\")\n",
    "print(\"Seasonally adjusted = Original - Seasonal Component\\n\")\n",
    "\n",
    "# Get best variables from refined model\n",
    "if 'refined_results' in globals() and refined_results is not None:\n",
    "    best_vars = refined_results['variables']\n",
    "    print(f\"Using best right-side variables: {', '.join(best_vars)}\")\n",
    "else:\n",
    "    if 'selected_rate_var' in globals():\n",
    "        primary_rate_var = selected_rate_var\n",
    "    else:\n",
    "        primary_rate_var = 'fed_funds_change'\n",
    "    best_vars = [primary_rate_var, 'vix_change', 'consumer_conf_change', 'disposable_income_change', 'saving_rate_change']\n",
    "    print(f\"Using default right-side variables: {', '.join(best_vars)}\")\n",
    "\n",
    "# Prepare data for seasonal adjustment\n",
    "# Need at least 2 years (24 months) for seasonal decomposition\n",
    "seasonal_tests = []\n",
    "\n",
    "# 1. Seasonally adjust excess returns (left-side variable)\n",
    "if 'excess_return' in data.columns:\n",
    "    excess_series = data['excess_return'].dropna()\n",
    "    \n",
    "    if len(excess_series) >= 24:  # Need at least 2 years for seasonal decomposition\n",
    "        try:\n",
    "            # Ensure index is datetime and sorted\n",
    "            excess_series = excess_series.sort_index()\n",
    "            \n",
    "            # Seasonal decomposition (additive model)\n",
    "            decomposition = seasonal_decompose(excess_series, model='additive', period=12, extrapolate_trend='freq')\n",
    "            \n",
    "            # Seasonally adjusted = original - seasonal component\n",
    "            excess_sa = excess_series - decomposition.seasonal\n",
    "            \n",
    "            # Test model with seasonally adjusted excess returns\n",
    "            test_data = data[best_vars].copy()\n",
    "            test_data['excess_return_sa'] = excess_sa.reindex(test_data.index)\n",
    "            test_data = test_data.dropna()\n",
    "            \n",
    "            if len(test_data) > 10:\n",
    "                X = test_data[best_vars].values\n",
    "                y = test_data['excess_return_sa'].values\n",
    "                X_const = sm.add_constant(X)\n",
    "                model = sm.OLS(y, X_const).fit(cov_type='HC3')\n",
    "                \n",
    "                seasonal_tests.append({\n",
    "                    'Specification': 'Excess Return (SA)',\n",
    "                    'R²': model.rsquared,\n",
    "                    'Adj R²': model.rsquared_adj,\n",
    "                    'N': len(y),\n",
    "                    'Description': 'Seasonally adjusted excess returns'\n",
    "                })\n",
    "                \n",
    "                print(f\"  ✓ Seasonally adjusted excess returns: R² = {model.rsquared:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠ Error seasonally adjusting excess returns: {str(e)[:80]}\")\n",
    "\n",
    "# 2. Seasonally adjust raw BNPL returns\n",
    "if 'bnpl_return' in data.columns:\n",
    "    bnpl_series = data['bnpl_return'].dropna()\n",
    "    \n",
    "    if len(bnpl_series) >= 24:\n",
    "        try:\n",
    "            bnpl_series = bnpl_series.sort_index()\n",
    "            decomposition = seasonal_decompose(bnpl_series, model='additive', period=12, extrapolate_trend='freq')\n",
    "            bnpl_sa = bnpl_series - decomposition.seasonal\n",
    "            \n",
    "            test_data = data[best_vars].copy()\n",
    "            test_data['bnpl_return_sa'] = bnpl_sa.reindex(test_data.index)\n",
    "            test_data = test_data.dropna()\n",
    "            \n",
    "            if len(test_data) > 10:\n",
    "                X = test_data[best_vars].values\n",
    "                y = test_data['bnpl_return_sa'].values\n",
    "                X_const = sm.add_constant(X)\n",
    "                model = sm.OLS(y, X_const).fit(cov_type='HC3')\n",
    "                \n",
    "                seasonal_tests.append({\n",
    "                    'Specification': 'Raw BNPL Return (SA)',\n",
    "                    'R²': model.rsquared,\n",
    "                    'Adj R²': model.rsquared_adj,\n",
    "                    'N': len(y),\n",
    "                    'Description': 'Seasonally adjusted raw BNPL returns'\n",
    "                })\n",
    "                \n",
    "                print(f\"  ✓ Seasonally adjusted BNPL returns: R² = {model.rsquared:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠ Error seasonally adjusting BNPL returns: {str(e)[:80]}\")\n",
    "\n",
    "# 3. Seasonally adjust key right-side variables\n",
    "# Test if seasonally adjusting independent variables improves fit\n",
    "print(\"\\nTesting seasonally adjusted right-side variables...\")\n",
    "\n",
    "# Seasonally adjust interest rate variable\n",
    "if 'selected_rate_var' in globals():\n",
    "    rate_var = selected_rate_var\n",
    "elif 'fed_funds_change' in data.columns:\n",
    "    rate_var = 'fed_funds_change'\n",
    "else:\n",
    "    rate_var = None\n",
    "\n",
    "if rate_var and rate_var in data.columns:\n",
    "    rate_series = data[rate_var].dropna()\n",
    "    \n",
    "    if len(rate_series) >= 24:\n",
    "        try:\n",
    "            rate_series = rate_series.sort_index()\n",
    "            decomposition = seasonal_decompose(rate_series, model='additive', period=12, extrapolate_trend='freq')\n",
    "            rate_sa = rate_series - decomposition.seasonal\n",
    "            \n",
    "            # Test with seasonally adjusted rate + other variables\n",
    "            test_data = data[best_vars].copy()\n",
    "            test_data[f'{rate_var}_sa'] = rate_sa.reindex(test_data.index)\n",
    "            \n",
    "            # Replace rate variable with seasonally adjusted version\n",
    "            sa_vars = [f'{rate_var}_sa' if v == rate_var else v for v in best_vars]\n",
    "            \n",
    "            if 'excess_return' in test_data.columns:\n",
    "                test_data = test_data[sa_vars + ['excess_return']].dropna()\n",
    "                \n",
    "                if len(test_data) > 10:\n",
    "                    X = test_data[sa_vars].values\n",
    "                    y = test_data['excess_return'].values\n",
    "                    X_const = sm.add_constant(X)\n",
    "                    model = sm.OLS(y, X_const).fit(cov_type='HC3')\n",
    "                    \n",
    "                    seasonal_tests.append({\n",
    "                        'Specification': 'Right-Side Variables (SA)',\n",
    "                        'R²': model.rsquared,\n",
    "                        'Adj R²': model.rsquared_adj,\n",
    "                        'N': len(y),\n",
    "                        'Description': f'Seasonally adjusted {rate_var} + other controls'\n",
    "                    })\n",
    "                    \n",
    "                    print(f\"  ✓ Seasonally adjusted {rate_var}: R² = {model.rsquared:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠ Error seasonally adjusting {rate_var}: {str(e)[:80]}\")\n",
    "\n",
    "# 4. Fully seasonally adjusted (both left and right side)\n",
    "if 'excess_return' in data.columns and rate_var:\n",
    "    excess_series = data['excess_return'].dropna()\n",
    "    rate_series = data[rate_var].dropna()\n",
    "    \n",
    "    if len(excess_series) >= 24 and len(rate_series) >= 24:\n",
    "        try:\n",
    "            excess_series = excess_series.sort_index()\n",
    "            rate_series = rate_series.sort_index()\n",
    "            \n",
    "            excess_decomp = seasonal_decompose(excess_series, model='additive', period=12, extrapolate_trend='freq')\n",
    "            rate_decomp = seasonal_decompose(rate_series, model='additive', period=12, extrapolate_trend='freq')\n",
    "            \n",
    "            excess_sa = excess_series - excess_decomp.seasonal\n",
    "            rate_sa = rate_series - rate_decomp.seasonal\n",
    "            \n",
    "            test_data = data[best_vars].copy()\n",
    "            test_data['excess_return_sa'] = excess_sa.reindex(test_data.index)\n",
    "            test_data[f'{rate_var}_sa'] = rate_sa.reindex(test_data.index)\n",
    "            \n",
    "            sa_vars = [f'{rate_var}_sa' if v == rate_var else v for v in best_vars]\n",
    "            test_data = test_data[sa_vars + ['excess_return_sa']].dropna()\n",
    "            \n",
    "            if len(test_data) > 10:\n",
    "                X = test_data[sa_vars].values\n",
    "                y = test_data['excess_return_sa'].values\n",
    "                X_const = sm.add_constant(X)\n",
    "                model = sm.OLS(y, X_const).fit(cov_type='HC3')\n",
    "                \n",
    "                seasonal_tests.append({\n",
    "                    'Specification': 'Fully Seasonally Adjusted',\n",
    "                    'R²': model.rsquared,\n",
    "                    'Adj R²': model.rsquared_adj,\n",
    "                    'N': len(y),\n",
    "                    'Description': 'Both left-side and right-side variables seasonally adjusted'\n",
    "                })\n",
    "                \n",
    "                print(f\"  ✓ Fully seasonally adjusted model: R² = {model.rsquared:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠ Error in fully seasonally adjusted model: {str(e)[:80]}\")\n",
    "\n",
    "# Compare with unadjusted baseline\n",
    "if 'excess_return' in data.columns:\n",
    "    test_data = data[best_vars + ['excess_return']].dropna()\n",
    "    if len(test_data) > 10:\n",
    "        X = test_data[best_vars].values\n",
    "        y = test_data['excess_return'].values\n",
    "        X_const = sm.add_constant(X)\n",
    "        baseline_model = sm.OLS(y, X_const).fit(cov_type='HC3')\n",
    "        \n",
    "        seasonal_tests.append({\n",
    "            'Specification': 'Baseline (Unadjusted)',\n",
    "            'R²': baseline_model.rsquared,\n",
    "            'Adj R²': baseline_model.rsquared_adj,\n",
    "            'N': len(y),\n",
    "            'Description': 'Original specification without seasonal adjustment'\n",
    "        })\n",
    "\n",
    "# Display results\n",
    "if len(seasonal_tests) > 0:\n",
    "    results_df = pd.DataFrame(seasonal_tests)\n",
    "    results_df = results_df.sort_values('R²', ascending=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESULTS: Seasonal Adjustment Comparison\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nRanked by R²:\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    best_sa = results_df.iloc[0]\n",
    "    baseline_r2 = results_df[results_df['Specification'] == 'Baseline (Unadjusted)']['R²'].values\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"BEST SEASONALLY ADJUSTED SPECIFICATION: {best_sa['Specification']}\")\n",
    "    print(f\"  R² = {best_sa['R²']:.4f}\")\n",
    "    print(f\"  Adjusted R² = {best_sa['Adj R²']:.4f}\")\n",
    "    print(f\"  Observations = {best_sa['N']}\")\n",
    "    print(f\"  Description: {best_sa['Description']}\")\n",
    "    \n",
    "    if len(baseline_r2) > 0:\n",
    "        improvement = best_sa['R²'] - baseline_r2[0]\n",
    "        print(f\"\\n  Improvement over baseline: {improvement:+.4f}\")\n",
    "        if improvement > 0.01:\n",
    "            print(f\"  ✓ Seasonal adjustment meaningfully improves model fit!\")\n",
    "        elif improvement > 0:\n",
    "            print(f\"  → Seasonal adjustment shows slight improvement\")\n",
    "        else:\n",
    "            print(f\"  → Seasonal adjustment does not improve fit\")\n",
    "    \n",
    "    if best_sa['R²'] >= 0.5:\n",
    "        print(f\"\\n  ✓ ACHIEVED TARGET: R² ≥ 0.5!\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"\\n⚠ Could not perform seasonal adjustment tests\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "log_transformation_testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOG TRANSFORMATION TESTING: Testing Log Specifications\n",
    "# ============================================================================\n",
    "# This section tests log transformations to see if multiplicative\n",
    "# relationships improve model fit and achieve R² > 0.5\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOG TRANSFORMATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nGoal: Test if log transformations improve model fit\")\n",
    "print(\"Rationale: Log transforms can capture multiplicative relationships,\")\n",
    "print(\"          reduce heteroskedasticity, and provide elasticity interpretations\\n\")\n",
    "\n",
    "# Get best variables from refined model\n",
    "if 'refined_results' in globals() and refined_results is not None:\n",
    "    best_vars = refined_results['variables']\n",
    "    print(f\"Using best right-side variables: {', '.join(best_vars)}\")\n",
    "else:\n",
    "    if 'selected_rate_var' in globals():\n",
    "        primary_rate_var = selected_rate_var\n",
    "    else:\n",
    "        primary_rate_var = 'fed_funds_change'\n",
    "    best_vars = [primary_rate_var, 'vix_change', 'consumer_conf_change', 'disposable_income_change', 'saving_rate_change']\n",
    "    print(f\"Using default right-side variables: {', '.join(best_vars)}\")\n",
    "\n",
    "log_tests = []\n",
    "\n",
    "# Helper function to safely apply log transformation\n",
    "def safe_log_transform(series, shift=0.01):\n",
    "    \"\"\"Apply log transformation with handling for negative/zero values\"\"\"\n",
    "    # For returns/change variables, shift to ensure positive values\n",
    "    # shift = 0.01 means we add 1% to handle negative returns\n",
    "    shifted = series + shift\n",
    "    return np.log(shifted)\n",
    "\n",
    "# 1. Log Excess Returns (left-side only)\n",
    "if 'excess_return' in data.columns:\n",
    "    excess_series = data['excess_return'].dropna()\n",
    "    \n",
    "    # Log transform: log(1 + excess_return/100) for percentage returns\n",
    "    # Or simpler: log(excess_return + shift) where shift ensures positivity\n",
    "    log_excess = np.log(1 + excess_series/100) * 100  # Standard log return formula\n",
    "    \n",
    "    test_data = data[best_vars].copy()\n",
    "    test_data['log_excess_return'] = log_excess.reindex(test_data.index)\n",
    "    test_data = test_data.dropna()\n",
    "    \n",
    "    if len(test_data) > 10:\n",
    "        X = test_data[best_vars].values\n",
    "        y = test_data['log_excess_return'].values\n",
    "        X_const = sm.add_constant(X)\n",
    "        model = sm.OLS(y, X_const).fit(cov_type='HC3')\n",
    "        \n",
    "        log_tests.append({\n",
    "            'Specification': 'Log Excess Returns',\n",
    "            'R²': model.rsquared,\n",
    "            'Adj R²': model.rsquared_adj,\n",
    "            'N': len(y),\n",
    "            'Description': 'Left-side: log(1 + excess_return/100), Right-side: linear'\n",
    "        })\n",
    "        \n",
    "        print(f\"  ✓ Log excess returns: R² = {model.rsquared:.4f}\")\n",
    "\n",
    "# 2. Log Raw BNPL Returns\n",
    "if 'bnpl_return' in data.columns:\n",
    "    bnpl_series = data['bnpl_return'].dropna()\n",
    "    log_bnpl = np.log(1 + bnpl_series/100) * 100\n",
    "    \n",
    "    test_data = data[best_vars].copy()\n",
    "    test_data['log_bnpl_return'] = log_bnpl.reindex(test_data.index)\n",
    "    test_data = test_data.dropna()\n",
    "    \n",
    "    if len(test_data) > 10:\n",
    "        X = test_data[best_vars].values\n",
    "        y = test_data['log_bnpl_return'].values\n",
    "        X_const = sm.add_constant(X)\n",
    "        model = sm.OLS(y, X_const).fit(cov_type='HC3')\n",
    "        \n",
    "        log_tests.append({\n",
    "            'Specification': 'Log BNPL Returns',\n",
    "            'R²': model.rsquared,\n",
    "            'Adj R²': model.rsquared_adj,\n",
    "            'N': len(y),\n",
    "            'Description': 'Left-side: log(1 + bnpl_return/100), Right-side: linear'\n",
    "        })\n",
    "        \n",
    "        print(f\"  ✓ Log BNPL returns: R² = {model.rsquared:.4f}\")\n",
    "\n",
    "# 3. Log-Log Model (both sides logged)\n",
    "# For this, we need to transform right-side variables too\n",
    "if 'excess_return' in data.columns:\n",
    "    excess_series = data['excess_return'].dropna()\n",
    "    log_excess = np.log(1 + excess_series/100) * 100\n",
    "    \n",
    "    # Get primary rate variable\n",
    "    if 'selected_rate_var' in globals():\n",
    "        rate_var = selected_rate_var\n",
    "    elif 'fed_funds_change' in data.columns:\n",
    "        rate_var = 'fed_funds_change'\n",
    "    else:\n",
    "        rate_var = None\n",
    "    \n",
    "    if rate_var and rate_var in data.columns:\n",
    "        rate_series = data[rate_var].dropna()\n",
    "        \n",
    "        # Log transform rate change (with shift for negative values)\n",
    "        # For change variables, use: log(rate_change + shift)\n",
    "        shift = abs(rate_series.min()) + 0.01 if rate_series.min() < 0 else 0.01\n",
    "        log_rate = np.log(rate_series + shift)\n",
    "        \n",
    "        # Prepare log-transformed right-side variables\n",
    "        test_data = data[best_vars].copy()\n",
    "        test_data['log_excess_return'] = log_excess.reindex(test_data.index)\n",
    "        test_data[f'log_{rate_var}'] = log_rate.reindex(test_data.index)\n",
    "        \n",
    "        # Create log-transformed variable list\n",
    "        log_vars = []\n",
    "        for var in best_vars:\n",
    "            if var == rate_var:\n",
    "                log_vars.append(f'log_{rate_var}')\n",
    "            else:\n",
    "                # For other variables, try log transform if they can be logged\n",
    "                var_series = data[var].dropna()\n",
    "                if var_series.min() < 0:\n",
    "                    shift_var = abs(var_series.min()) + 0.01\n",
    "                else:\n",
    "                    shift_var = 0.01\n",
    "                log_var_series = np.log(var_series + shift_var)\n",
    "                test_data[f'log_{var}'] = log_var_series.reindex(test_data.index)\n",
    "                log_vars.append(f'log_{var}')\n",
    "        \n",
    "        test_data = test_data[log_vars + ['log_excess_return']].dropna()\n",
    "        \n",
    "        if len(test_data) > 10:\n",
    "            X = test_data[log_vars].values\n",
    "            y = test_data['log_excess_return'].values\n",
    "            X_const = sm.add_constant(X)\n",
    "            model = sm.OLS(y, X_const).fit(cov_type='HC3')\n",
    "            \n",
    "            log_tests.append({\n",
    "                'Specification': 'Log-Log Model',\n",
    "                'R²': model.rsquared,\n",
    "                'Adj R²': model.rsquared_adj,\n",
    "                'N': len(y),\n",
    "                'Description': 'Both left-side and right-side variables log-transformed'\n",
    "            })\n",
    "            \n",
    "            print(f\"  ✓ Log-log model: R² = {model.rsquared:.4f}\")\n",
    "\n",
    "# 4. Semi-Log Model (log left-side, linear right-side)\n",
    "if 'excess_return' in data.columns:\n",
    "    excess_series = data['excess_return'].dropna()\n",
    "    log_excess = np.log(1 + excess_series/100) * 100\n",
    "    \n",
    "    test_data = data[best_vars].copy()\n",
    "    test_data['log_excess_return'] = log_excess.reindex(test_data.index)\n",
    "    test_data = test_data.dropna()\n",
    "    \n",
    "    if len(test_data) > 10:\n",
    "        X = test_data[best_vars].values\n",
    "        y = test_data['log_excess_return'].values\n",
    "        X_const = sm.add_constant(X)\n",
    "        model = sm.OLS(y, X_const).fit(cov_type='HC3')\n",
    "        \n",
    "        log_tests.append({\n",
    "            'Specification': 'Semi-Log Model',\n",
    "            'R²': model.rsquared,\n",
    "            'Adj R²': model.rsquared_adj,\n",
    "            'N': len(y),\n",
    "            'Description': 'Log left-side, linear right-side (elasticity interpretation)'\n",
    "        })\n",
    "        \n",
    "        print(f\"  ✓ Semi-log model: R² = {model.rsquared:.4f}\")\n",
    "\n",
    "# 5. Box-Cox Transformation (optimal power transformation)\n",
    "from scipy import stats\n",
    "\n",
    "if 'excess_return' in data.columns:\n",
    "    excess_series = data['excess_return'].dropna()\n",
    "    \n",
    "    # Box-Cox requires positive values, so shift if needed\n",
    "    if excess_series.min() <= 0:\n",
    "        shift = abs(excess_series.min()) + 1\n",
    "        excess_shifted = excess_series + shift\n",
    "    else:\n",
    "        excess_shifted = excess_series\n",
    "    \n",
    "    try:\n",
    "        # Find optimal lambda for Box-Cox\n",
    "        excess_transformed, lambda_bc = stats.boxcox(excess_shifted)\n",
    "        \n",
    "        test_data = data[best_vars].copy()\n",
    "        test_data['boxcox_excess'] = pd.Series(excess_transformed, index=excess_shifted.index).reindex(test_data.index)\n",
    "        test_data = test_data.dropna()\n",
    "        \n",
    "        if len(test_data) > 10:\n",
    "            X = test_data[best_vars].values\n",
    "            y = test_data['boxcox_excess'].values\n",
    "            X_const = sm.add_constant(X)\n",
    "            model = sm.OLS(y, X_const).fit(cov_type='HC3')\n",
    "            \n",
    "            log_tests.append({\n",
    "                'Specification': 'Box-Cox Transformation',\n",
    "                'R²': model.rsquared,\n",
    "                'Adj R²': model.rsquared_adj,\n",
    "                'N': len(y),\n",
    "                'Description': f'Box-Cox optimal transformation (lambda={lambda_bc:.3f})'\n",
    "            })\n",
    "            \n",
    "            print(f\"  ✓ Box-Cox transformation (λ={lambda_bc:.3f}): R² = {model.rsquared:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠ Box-Cox transformation failed: {str(e)[:80]}\")\n",
    "\n",
    "# Compare with linear baseline\n",
    "if 'excess_return' in data.columns:\n",
    "    test_data = data[best_vars + ['excess_return']].dropna()\n",
    "    if len(test_data) > 10:\n",
    "        X = test_data[best_vars].values\n",
    "        y = test_data['excess_return'].values\n",
    "        X_const = sm.add_constant(X)\n",
    "        baseline_model = sm.OLS(y, X_const).fit(cov_type='HC3')\n",
    "        \n",
    "        log_tests.append({\n",
    "            'Specification': 'Linear (Baseline)',\n",
    "            'R²': baseline_model.rsquared,\n",
    "            'Adj R²': baseline_model.rsquared_adj,\n",
    "            'N': len(y),\n",
    "            'Description': 'Original linear specification (no transformations)'\n",
    "        })\n",
    "\n",
    "# Display results\n",
    "if len(log_tests) > 0:\n",
    "    results_df = pd.DataFrame(log_tests)\n",
    "    results_df = results_df.sort_values('R²', ascending=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESULTS: Log Transformation Comparison\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nRanked by R²:\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    best_log = results_df.iloc[0]\n",
    "    baseline_r2 = results_df[results_df['Specification'] == 'Linear (Baseline)']['R²'].values\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"BEST LOG TRANSFORMATION: {best_log['Specification']}\")\n",
    "    print(f\"  R² = {best_log['R²']:.4f}\")\n",
    "    print(f\"  Adjusted R² = {best_log['Adj R²']:.4f}\")\n",
    "    print(f\"  Observations = {best_log['N']}\")\n",
    "    print(f\"  Description: {best_log['Description']}\")\n",
    "    \n",
    "    if len(baseline_r2) > 0:\n",
    "        improvement = best_log['R²'] - baseline_r2[0]\n",
    "        print(f\"\\n  Improvement over linear: {improvement:+.4f}\")\n",
    "        if improvement > 0.01:\n",
    "            print(f\"  ✓ Log transformation meaningfully improves model fit!\")\n",
    "        elif improvement > 0:\n",
    "            print(f\"  → Log transformation shows slight improvement\")\n",
    "        else:\n",
    "            print(f\"  → Linear specification remains optimal\")\n",
    "    \n",
    "    if best_log['R²'] >= 0.5:\n",
    "        print(f\"\\n  ✓ ACHIEVED TARGET: R² ≥ 0.5!\")\n",
    "    \n",
    "    print(\"\\nInterpretation:\")\n",
    "    if 'Log' in best_log['Specification']:\n",
    "        print(\"  • Log transforms capture multiplicative relationships\")\n",
    "        print(\"  • Coefficients can be interpreted as elasticities\")\n",
    "        print(\"  • Better handles heteroskedasticity and skewness\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"\\n⚠ Could not perform log transformation tests\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple_test_output",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SIMPLE TEST: Check What Variables Exist\n",
    "# ============================================================================\n",
    "# Run this FIRST to see what's available\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHECKING AVAILABLE VARIABLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check if key variables exist\n",
    "checks = {\n",
    "    'data': 'data' in globals(),\n",
    "    'refined_data': 'refined_data' in globals(),\n",
    "    'refined_results': 'refined_results' in globals(),\n",
    "    'best_model': 'best_model' in globals(),\n",
    "    'selected_rate_var': 'selected_rate_var' in globals(),\n",
    "    'excess_regression_results': 'excess_regression_results' in globals()\n",
    "}\n",
    "\n",
    "for var_name, exists in checks.items():\n",
    "    status = \"✓ EXISTS\" if exists else \"✗ MISSING\"\n",
    "    print(f\"{status}: {var_name}\")\n",
    "\n",
    "# Show current R² if available\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CURRENT R² VALUES:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'excess_regression_results' in globals():\n",
    "    baseline_r2 = excess_regression_results.get('r2', None)\n",
    "    print(f\"\\nBaseline (Bivariate): R² = {baseline_r2:.4f}\" if baseline_r2 else \"\\nBaseline: Not calculated\")\n",
    "else:\n",
    "    print(\"\\nBaseline: Not found - run baseline regression cell first\")\n",
    "\n",
    "if 'refined_results' in globals() and refined_results is not None:\n",
    "    current_r2 = refined_results.get('r_squared', None)\n",
    "    current_adj_r2 = refined_results.get('adj_r_squared', None)\n",
    "    print(f\"\\nCurrent Best Model:\")\n",
    "    print(f\"  R² = {current_r2:.4f}\" if current_r2 else \"  R² = Not calculated\")\n",
    "    print(f\"  Adjusted R² = {current_adj_r2:.4f}\" if current_adj_r2 else \"  Adjusted R² = Not calculated\")\n",
    "    vars_list = refined_results.get('variables', [])\n",
    "    if vars_list:\n",
    "        print(f\"  Variables: {', '.join(vars_list)}\")\n",
    "else:\n",
    "    print(\"\\nCurrent Best Model: Not found - run Step 2 cell first\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NEXT STEPS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nTo see improvements, run these cells IN ORDER:\")\n",
    "print(\"  1. Cell with baseline regression (if not run yet)\")\n",
    "print(\"  2. Cell with Step 2 (5-variable model selection)\")\n",
    "print(\"  3. Cell 14: Step 3 (expanded variable pool - 210 combinations)\")\n",
    "print(\"  4. Cell 19: Diagnostic check (shows all improvements)\")\n",
    "print(\"\\nAfter running Step 3, you should see:\")\n",
    "print(\"  - 'Best Model (from expanded pool)' with R² values\")\n",
    "print(\"  - 'Improvement: +X.XXXX' showing how much better it is\")\n",
    "print(\"  - '✓ Updated best_model' if improvement > 0\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check_improvements",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# QUICK CHECK: What Improvements Have We Found?\n",
    "# ============================================================================\n",
    "# Run this cell to see current R² values and improvements\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CURRENT MODEL PERFORMANCE CHECK\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check baseline\n",
    "baseline_r2 = None\n",
    "if 'excess_regression_results' in globals():\n",
    "    baseline_r2 = excess_regression_results.get('r2', None)\n",
    "    print(f\"\\n✓ Baseline Model (Bivariate): R² = {baseline_r2:.4f}\")\n",
    "else:\n",
    "    print(\"\\n⚠ Baseline model not found - run baseline regression cell first\")\n",
    "\n",
    "# Check Step 2 (original 5-variable)\n",
    "step2_r2 = None\n",
    "step2_adj_r2 = None\n",
    "if 'refined_results' in globals() and refined_results is not None:\n",
    "    step2_r2 = refined_results.get('r_squared', None)\n",
    "    step2_adj_r2 = refined_results.get('adj_r_squared', None)\n",
    "    print(f\"\\n✓ Step 2 (Original 5-Variable Model):\")\n",
    "    print(f\"   R² = {step2_r2:.4f}\")\n",
    "    print(f\"   Adjusted R² = {step2_adj_r2:.4f}\")\n",
    "    if baseline_r2:\n",
    "        improvement = step2_r2 - baseline_r2\n",
    "        print(f\"   Improvement over baseline: {improvement:+.4f} ({improvement/baseline_r2*100:+.1f}%)\")\n",
    "else:\n",
    "    print(\"\\n⚠ Step 2 model not found - run Step 2 cell first\")\n",
    "\n",
    "# Check if Step 3 improved it\n",
    "if 'refined_results' in globals() and refined_results is not None:\n",
    "    current_r2 = refined_results.get('r_squared', None)\n",
    "    current_adj_r2 = refined_results.get('adj_r_squared', None)\n",
    "    current_vars = refined_results.get('variables', None)\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(\"CURRENT BEST MODEL:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nR² = {current_r2:.4f}\")\n",
    "    print(f\"Adjusted R² = {current_adj_r2:.4f}\")\n",
    "    print(f\"\\nVariables: {', '.join(current_vars) if current_vars else 'N/A'}\")\n",
    "    \n",
    "    if step2_r2 and abs(current_r2 - step2_r2) > 0.001:\n",
    "        step3_improvement = current_r2 - step2_r2\n",
    "        print(f\"\\n✓ STEP 3 IMPROVEMENT FOUND!\")\n",
    "        print(f\"   Improvement from Step 2: {step3_improvement:+.4f}\")\n",
    "        print(f\"   This means Step 3 (expanded variable pool) found a better model!\")\n",
    "    else:\n",
    "        print(f\"\\n→ Current model is from Step 2 (Step 3 may not have improved it)\")\n",
    "        print(f\"→ Run Step 3 cell to test 210 combinations from expanded variable pool\")\n",
    "    \n",
    "    # Check against target\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(\"TARGET CHECK:\")\n",
    "    print(\"=\"*80)\n",
    "    if current_r2 >= 0.5:\n",
    "        print(f\"\\n✓✓✓ TARGET ACHIEVED! R² = {current_r2:.4f} ≥ 0.5 ✓✓✓\")\n",
    "    elif current_r2 >= 0.4:\n",
    "        print(f\"\\n→ Close! R² = {current_r2:.4f} (need {0.5 - current_r2:.4f} more to reach 0.5)\")\n",
    "        print(f\"→ Try running:\")\n",
    "        print(f\"   - Cell 16: Alternative left-side variables\")\n",
    "        print(f\"   - Cell 17: Seasonal adjustment\")\n",
    "        print(f\"   - Cell 18: Log transformations\")\n",
    "    else:\n",
    "        print(f\"\\n→ Current R² = {current_r2:.4f} (target: 0.5)\")\n",
    "        print(f\"→ Need {0.5 - current_r2:.4f} more to reach target\")\n",
    "        print(f\"→ Try running:\")\n",
    "        print(f\"   - Cell 14: Step 3 (expanded variable pool - 210 combinations)\")\n",
    "        print(f\"   - Cell 16: Alternative left-side variables\")\n",
    "        print(f\"   - Cell 17: Seasonal adjustment\")\n",
    "        print(f\"   - Cell 18: Log transformations\")\n",
    "else:\n",
    "    print(\"\\n⚠ No refined model found. Run model selection cells first.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "improvement_summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL IMPROVEMENT SUMMARY\n",
      "================================================================================\n",
      "\n",
      "4. ALTERNATIVE LEFT-SIDE VARIABLES:\n",
      "   → Run Cell 16 to test: Raw returns, Sector benchmarks, Log returns, Individual stocks\n",
      "   → Results will show if changing dependent variable improves R²\n",
      "\n",
      "5. SEASONAL ADJUSTMENT:\n",
      "   → Run Cell 17 to test: Seasonally adjusted left/right-side variables\n",
      "   → Results will show if removing seasonal patterns improves R²\n",
      "\n",
      "6. LOG TRANSFORMATIONS:\n",
      "   → Run Cell 18 to test: Log returns, Log-log model, Box-Cox transformation\n",
      "   → Results will show if multiplicative relationships improve R²\n",
      "\n",
      "================================================================================\n",
      "CURRENT BEST MODEL:\n",
      "================================================================================\n",
      "\n",
      "⚠ No model results found. Run model selection cells first.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# IMPROVEMENT SUMMARY: All Model Improvements Found\n",
    "# ============================================================================\n",
    "# This cell summarizes all improvements found across different testing approaches\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL IMPROVEMENT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Baseline Model R²\n",
    "baseline_r2 = None\n",
    "if 'excess_regression_results' in globals():\n",
    "    baseline_r2 = excess_regression_results.get('r2', None)\n",
    "    print(f\"\\n1. BASELINE MODEL (Bivariate):\")\n",
    "    print(f\"   R² = {baseline_r2:.4f}\" if baseline_r2 else \"   R² = Not yet calculated\")\n",
    "\n",
    "# 2. Step 2: Original 5-Variable Model\n",
    "step2_r2 = None\n",
    "step2_adj_r2 = None\n",
    "if 'refined_results' in globals() and refined_results is not None:\n",
    "    step2_r2 = refined_results.get('r_squared', None)\n",
    "    step2_adj_r2 = refined_results.get('adj_r_squared', None)\n",
    "    print(f\"\\n2. STEP 2: Original 5-Variable Model (from 6 candidate variables):\")\n",
    "    print(f\"   R² = {step2_r2:.4f}\" if step2_r2 else \"   R² = Not yet calculated\")\n",
    "    print(f\"   Adjusted R² = {step2_adj_r2:.4f}\" if step2_adj_r2 else \"   Adjusted R² = Not yet calculated\")\n",
    "    if baseline_r2 and step2_r2:\n",
    "        improvement = step2_r2 - baseline_r2\n",
    "        print(f\"   Improvement over baseline: {improvement:+.4f} ({improvement/baseline_r2*100:+.1f}%)\")\n",
    "\n",
    "# 3. Step 3: Expanded Variable Pool (210 combinations)\n",
    "step3_r2 = None\n",
    "step3_adj_r2 = None\n",
    "step3_vars = None\n",
    "if 'refined_results' in globals() and refined_results is not None:\n",
    "    # Check if refined_results was updated by Step 3\n",
    "    step3_r2 = refined_results.get('r_squared', None)\n",
    "    step3_adj_r2 = refined_results.get('adj_r_squared', None)\n",
    "    step3_vars = refined_results.get('variables', None)\n",
    "    \n",
    "    # Check if this is different from Step 2 (meaning Step 3 updated it)\n",
    "    if step3_r2 and step2_r2 and abs(step3_r2 - step2_r2) > 0.001:\n",
    "        print(f\"\\n3. STEP 3: Expanded Variable Pool (210 combinations tested):\")\n",
    "        print(f\"   R² = {step3_r2:.4f}\")\n",
    "        print(f\"   Adjusted R² = {step3_adj_r2:.4f}\")\n",
    "        print(f\"   Variables: {', '.join(step3_vars) if step3_vars else 'N/A'}\")\n",
    "        improvement = step3_r2 - step2_r2\n",
    "        print(f\"   Improvement over Step 2: {improvement:+.4f} ({improvement/step2_r2*100:+.1f}%)\")\n",
    "    else:\n",
    "        print(f\"\\n3. STEP 3: Expanded Variable Pool:\")\n",
    "        print(f\"   → No improvement found (Step 2 model remains best)\")\n",
    "        print(f\"   → Run Step 3 cell to see detailed comparison\")\n",
    "\n",
    "# 4. Alternative Left-Side Variables\n",
    "print(f\"\\n4. ALTERNATIVE LEFT-SIDE VARIABLES:\")\n",
    "print(f\"   → Run Cell 16 to test: Raw returns, Sector benchmarks, Log returns, Individual stocks\")\n",
    "print(f\"   → Results will show if changing dependent variable improves R²\")\n",
    "\n",
    "# 5. Seasonal Adjustment\n",
    "print(f\"\\n5. SEASONAL ADJUSTMENT:\")\n",
    "print(f\"   → Run Cell 17 to test: Seasonally adjusted left/right-side variables\")\n",
    "print(f\"   → Results will show if removing seasonal patterns improves R²\")\n",
    "\n",
    "# 6. Log Transformations\n",
    "print(f\"\\n6. LOG TRANSFORMATIONS:\")\n",
    "print(f\"   → Run Cell 18 to test: Log returns, Log-log model, Box-Cox transformation\")\n",
    "print(f\"   → Results will show if multiplicative relationships improve R²\")\n",
    "\n",
    "# Overall Summary\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"CURRENT BEST MODEL:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'refined_results' in globals() and refined_results is not None:\n",
    "    best_r2 = refined_results.get('r_squared', None)\n",
    "    best_adj_r2 = refined_results.get('adj_r_squared', None)\n",
    "    best_vars = refined_results.get('variables', None)\n",
    "    \n",
    "    print(f\"\\nBest R² Found: {best_r2:.4f}\" if best_r2 else \"Best R²: Not yet calculated\")\n",
    "    print(f\"Best Adjusted R²: {best_adj_r2:.4f}\" if best_adj_r2 else \"Best Adjusted R²: Not yet calculated\")\n",
    "    print(f\"Variables: {', '.join(best_vars) if best_vars else 'Not yet selected'}\")\n",
    "    \n",
    "    if best_r2:\n",
    "        if best_r2 >= 0.5:\n",
    "            print(f\"\\n✓ TARGET ACHIEVED: R² ≥ 0.5!\")\n",
    "        elif best_r2 >= 0.4:\n",
    "            print(f\"\\n→ Close to target: R² = {best_r2:.4f} (target: 0.5)\")\n",
    "            print(f\"→ Try running alternative left-side, seasonal adjustment, or log transformation cells\")\n",
    "        else:\n",
    "            print(f\"\\n→ Current R² = {best_r2:.4f} (target: 0.5)\")\n",
    "            print(f\"→ To improve further:\")\n",
    "            print(f\"   1. Run Cell 16: Test alternative left-side variables\")\n",
    "            print(f\"   2. Run Cell 17: Test seasonal adjustment\")\n",
    "            print(f\"   3. Run Cell 18: Test log transformations\")\n",
    "else:\n",
    "    print(\"\\n⚠ No model results found. Run model selection cells first.\")\n",
    "\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable_improvement_interpretation",
   "metadata": {},
   "source": [
    "### Variable Improvement Analysis: Results and Interpretation\n",
    "\n",
    "The expanded variable testing evaluates whether alternative variables can improve upon the current 5-variable specification. By testing additional candidate variables within the same 5-variable framework, we determine whether **better variable choices** exist rather than simply adding more variables.\n",
    "\n",
    "**Key Findings:**\n",
    "\n",
    "The comparison between the original variable pool and the expanded pool reveals whether:\n",
    "\n",
    "1. **New variables improve model fit**: If the best model from the expanded pool shows meaningful improvement (adjusted R² increase >0.01), it suggests that the additional variables capture important channels not fully captured by the original variables.\n",
    "\n",
    "2. **Original variables remain optimal**: If improvement is minimal or negative, it confirms that our initial variable selection was appropriate and that the original variables effectively capture the key economic mechanisms affecting BNPL excess returns.\n",
    "\n",
    "3. **Variable substitution opportunities**: The results show which specific variables from the expanded pool (if any) should replace existing variables in the optimal specification.\n",
    "\n",
    "**Interpretation of Additional Variables:**\n",
    "\n",
    "If any of the additional variables appear in the best-performing models:\n",
    "\n",
    "- **Unemployment Rate Change**: Would indicate that labor market conditions directly affect BNPL stock performance, consistent with CFPB (2025) findings that 57.9% of BNPL users experienced income disruptions.\n",
    "\n",
    "- **Consumer Credit Growth**: Would suggest that broader credit market conditions affect BNPL firms' competitive position and growth prospects.\n",
    "\n",
    "- **CPI Inflation Rate**: Would indicate that purchasing power effects directly impact BNPL demand and usage patterns.\n",
    "\n",
    "- **Market Return (SPY)**: Would control for systematic market movements, helping isolate BNPL-specific effects from general market trends.\n",
    "\n",
    "**Final Model Selection:**\n",
    "\n",
    "Based on the comparison results, we select the model specification (from either the original or expanded pool) that achieves the highest adjusted R² while maintaining theoretical coherence. This ensures we use the **best combination of 5 variables** available, whether from the original candidate pool or including improved alternatives identified through expanded testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended_model_interpretation",
   "metadata": {},
   "source": [
    "### Improved Variable Testing: Testing Additional Candidate Variables\n",
    "\n",
    "To determine whether we can improve beyond the current 5-variable refined model (R² = 0.2103), we test additional candidate variables that may better capture BNPL excess return dynamics. Rather than adding more variables, we test whether **replacing** existing variables with better alternatives improves model fit.\n",
    "\n",
    "**Additional Candidate Variables:**\n",
    "\n",
    "Based on economic theory and empirical evidence from CFPB (2025), Chargeflow (2025), and Digital Silk (2025), we test the following additional variables:\n",
    "\n",
    "1. **Unemployment Rate Change**: Captures labor market stress affecting BNPL users' ability to repay. CFPB (2025) documents that 57.9% of BNPL users experienced income disruptions, making unemployment particularly relevant.\n",
    "\n",
    "2. **Consumer Credit Growth**: Captures credit availability in the broader consumer credit market. CFPB (2025) shows BNPL borrowers have higher credit card utilization (60-66% vs 34%), suggesting credit availability affects BNPL demand.\n",
    "\n",
    "3. **CPI Inflation Rate**: Captures purchasing power effects. Digital Silk (2025) reports that 55% of users choose BNPL to afford things they otherwise couldn't, suggesting inflation affects BNPL usage.\n",
    "\n",
    "4. **Market Return (SPY)**: Controls for systematic market movements, isolating BNPL-specific effects from general market trends.\n",
    "\n",
    "**Testing Approach:**\n",
    "\n",
    "We expand our candidate pool to include these additional variables and test **all possible 5-variable combinations** from the expanded pool. This allows us to determine whether any of the new variables should replace existing ones in the optimal specification. We maintain the 5-variable framework to preserve parsimony while exploring whether better variable choices exist.\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "If the expanded variable pool yields a model with meaningfully higher adjusted R² (>0.01 improvement), it suggests that the additional variables capture important channels not fully captured by the original variables. If improvement is minimal, the original variable pool remains optimal, confirming that our initial variable selection was appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_model_summary",
   "metadata": {},
   "source": [
    "### Final Selected Model: Complete Specification\n",
    "\n",
    "After systematic testing of both left-side (interest rate) and right-side (control) variables, we have identified the optimal model specification:\n",
    "\n",
    "**LEFT SIDE VARIABLE (Selected through Step 1):**\n",
    "\n",
    "- **Selected Variable**: Prime Rate (Prime_Rate)\n",
    "- **Selection Method**: Empirical testing of 4 alternative interest rate variables\n",
    "- **Selection Criterion**: Highest Adjusted R²\n",
    "- **Result**: Prime Rate achieved the highest adjusted R² (0.0554) among all tested interest rate variables\n",
    "\n",
    "**RIGHT SIDE VARIABLES (Selected through Step 2):**\n",
    "\n",
    "- **Selected Variables**: The four control variables shown in the \"SELECTED BEST MODEL\" output above\n",
    "- **Selection Method**: Systematic testing of all C(6,4) = 15 combinations of control variables\n",
    "- **Selection Criterion**: Highest Adjusted R²\n",
    "- **Result**: The optimal combination of 4 control variables was identified through exhaustive testing\n",
    "\n",
    "**COMPLETE MODEL:**\n",
    "\n",
    "The final model specification is:\n",
    "\n",
    "**Excess_Return_t = β₀ + β₁(Prime_Rate_t) + β₂(Control_Var_1_t) + β₃(Control_Var_2_t) + β₄(Control_Var_3_t) + β₅(Control_Var_4_t) + ε_t**\n",
    "\n",
    "Where the specific control variables are determined by the model selection algorithm and displayed in the \"SELECTED BEST MODEL\" output. This two-stage selection process ensures that both the interest rate variable and the control variables are chosen empirically, maximizing model fit while maintaining theoretical coherence with the economic mechanisms documented in CFPB (2025), Chargeflow (2025), and Digital Silk (2025) reports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined_model_detailed_interpretation",
   "metadata": {},
   "source": [
    "### Refined Multi-Factor Model: Detailed Results and Interpretation\n",
    "\n",
    "The refined multi-factor model represents a significant improvement over the baseline specification by incorporating multiple economic channels that jointly determine BNPL excess returns. Through systematic testing of **all possible 5-variable combinations** from our candidate pool, we identified the optimal specification that maximizes adjusted R² while maintaining theoretical coherence with the empirical patterns documented in CFPB (2025), Chargeflow (2025), and Digital Silk (2025) reports.\n",
    "\n",
    "**Understanding the R² Values:**\n",
    "\n",
    "- **Baseline Model R² ≈ 0.03-0.06**: This is the R² from the simple bivariate regression using only the interest rate variable (Prime Rate). It shows that interest rates alone explain only 3-6% of variation in BNPL excess returns.\n",
    "\n",
    "- **Refined Model R² = 0.2103**: This is the R² from the **best** 5-variable model identified through systematic testing. It includes Prime Rate plus the optimal combination of 4 control variables. The increase from ~0.03-0.06 to 0.2103 demonstrates that adding the right control variables substantially improves model fit.\n",
    "\n",
    "**Model Selection Process:**\n",
    "\n",
    "The model selection process tested all combinations of 5 variables from our candidate pool, which includes the selected interest rate variable (Prime Rate, based on empirical testing) plus control variables capturing distinct economic mechanisms: VIX Change (market volatility), Retail Sales Growth (consumer spending), Consumer Confidence Change (spending intentions), Credit Spread Change (credit market conditions), Personal Saving Rate Change (financial vulnerability), and Disposable Income Growth (income channel). Each combination was evaluated using adjusted R² to account for model complexity, ensuring we select a specification that balances explanatory power with parsimony.\n",
    "\n",
    "**Selected Model Specification:**\n",
    "\n",
    "The selected refined model includes the following variables: (1) **Prime Rate Change**, the empirically selected interest rate variable that best captures BNPL sensitivity to consumer credit market conditions; (2-5) **Four control variables** selected through systematic testing that capture distinct economic channels affecting BNPL performance. The specific variables included in the final specification are determined by the model selection algorithm, which identifies the combination that maximizes adjusted R² while maintaining statistical significance.\n",
    "\n",
    "**Key Findings from the Refined Model:**\n",
    "\n",
    "The refined model reveals that BNPL excess returns are determined by multiple economic factors beyond interest rates alone. The coefficient on Prime Rate Change in the refined specification represents the direct effect of interest rate changes on BNPL excess returns, controlling for other economic factors. This coefficient is expected to be negative, reflecting that higher interest rates increase BNPL firms' funding costs and reduce profitability, leading to lower stock returns relative to the market.\n",
    "\n",
    "The control variables in the refined model capture additional channels affecting BNPL performance. For example, Retail Sales Growth captures the demand-side channel documented by Digital Silk (2025), where BNPL users spend 6% more online than non-BNPL shoppers. Credit Spread Change captures credit market tightness, particularly relevant given that 61% of BNPL borrowers are subprime or deep subprime according to CFPB (2025). Personal Saving Rate Change captures financial vulnerability patterns, as CFPB (2025) found that 77.7% of BNPL users relied on financial coping strategies.\n",
    "\n",
    "**Model Comparison and Improvement:**\n",
    "\n",
    "The refined model achieves an R² of **0.2103**, representing a substantial improvement over the baseline model's R² of approximately **0.03-0.06**. This improvement demonstrates that multiple economic channels jointly determine BNPL excess returns, not just interest rate sensitivity. The increase in R² from approximately 0.03-0.06 to 0.2103 indicates that the selected control variables explain an additional **15-18 percentage points** of variation in BNPL excess returns beyond what can be explained by interest rates alone. This represents approximately a **350-600% increase** in explanatory power, demonstrating the value of systematically selecting control variables rather than relying on interest rates alone.\n",
    "\n",
    "This finding is consistent with the complex business model of BNPL firms, which are affected by consumer spending patterns, credit market conditions, financial stress indicators, and market sentiment in addition to funding costs. The refined model allows us to isolate the direct effect of interest rate changes on BNPL excess returns while controlling for confounding factors, providing a cleaner estimate of BNPL-specific sensitivity to monetary policy separate from general economic conditions that affect all financial stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf489dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: TEST LEFT SIDE VARIABLE (Interest Rate Selection)\n",
    "# ============================================================================\n",
    "# This section tests alternative interest rate variables to identify\n",
    "# which one best captures BNPL excess return sensitivity.\n",
    "# We test: Federal Funds Rate, 3-Month Treasury, Commercial Paper, Prime Rate\n",
    "# ============================================================================\n",
    "\n",
    "# Interest Rate Variable Comparison: Test Alternatives to FFR\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TESTING ALTERNATIVE INTEREST RATE VARIABLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load alternative interest rate variables\n",
    "alt_rates = {}\n",
    "\n",
    "try:\n",
    "    # 3-Month Treasury Rate\n",
    "    treasury_3m = web.DataReader('DGS3MO', 'fred', start_date, end_date)\n",
    "    treasury_3m_change = treasury_3m['DGS3MO'].diff()\n",
    "    if treasury_3m_change.index.tz is not None:\n",
    "        treasury_3m_change.index = treasury_3m_change.index.tz_localize(None)\n",
    "    treasury_3m_change.index = pd.to_datetime(treasury_3m_change.index).to_period('M').to_timestamp('M')\n",
    "    alt_rates['3M_Treasury'] = treasury_3m_change\n",
    "    print(\"  ✓ Loaded 3-Month Treasury Rate\")\n",
    "except Exception as e:\n",
    "    print(f\"  ⚠ Error loading 3-Month Treasury: {str(e)[:50]}\")\n",
    "\n",
    "try:\n",
    "    # Commercial Paper Rate (3-Month, Nonfinancial)\n",
    "    cp_rate = web.DataReader('CPN3M', 'fred', start_date, end_date)\n",
    "    cp_rate_change = cp_rate['CPN3M'].diff()\n",
    "    if cp_rate_change.index.tz is not None:\n",
    "        cp_rate_change.index = cp_rate_change.index.tz_localize(None)\n",
    "    cp_rate_change.index = pd.to_datetime(cp_rate_change.index).to_period('M').to_timestamp('M')\n",
    "    alt_rates['Commercial_Paper'] = cp_rate_change\n",
    "    print(\"  ✓ Loaded Commercial Paper Rate\")\n",
    "except Exception as e:\n",
    "    print(f\"  ⚠ Error loading Commercial Paper: {str(e)[:50]}\")\n",
    "\n",
    "try:\n",
    "    # Prime Rate\n",
    "    prime_rate = web.DataReader('PRIME', 'fred', start_date, end_date)\n",
    "    prime_rate_change = prime_rate['PRIME'].diff()\n",
    "    if prime_rate_change.index.tz is not None:\n",
    "        prime_rate_change.index = prime_rate_change.index.tz_localize(None)\n",
    "    prime_rate_change.index = pd.to_datetime(prime_rate_change.index).to_period('M').to_timestamp('M')\n",
    "    alt_rates['Prime_Rate'] = prime_rate_change\n",
    "    print(\"  ✓ Loaded Prime Rate\")\n",
    "except Exception as e:\n",
    "    print(f\"  ⚠ Error loading Prime Rate: {str(e)[:50]}\")\n",
    "\n",
    "# Prepare comparison dataset\n",
    "comparison_data = data[['excess_return', 'fed_funds_change']].copy()\n",
    "\n",
    "# Add alternative rates\n",
    "for name, rate_series in alt_rates.items():\n",
    "    comparison_data = comparison_data.join(rate_series.to_frame(name), how='inner')\n",
    "\n",
    "comparison_data = comparison_data.dropna()\n",
    "\n",
    "print(f\"\\n  Comparison dataset: {len(comparison_data)} observations\")\n",
    "print(f\"  Date range: {comparison_data.index.min()} to {comparison_data.index.max()}\")\n",
    "\n",
    "# Test each rate variable\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REGRESSION RESULTS BY INTEREST RATE VARIABLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rate_comparison = []\n",
    "\n",
    "# Test FFR (baseline)\n",
    "X_ffr = comparison_data[['fed_funds_change']].values\n",
    "y = comparison_data['excess_return'].values\n",
    "X_ffr_const = sm.add_constant(X_ffr)\n",
    "model_ffr = sm.OLS(y, X_ffr_const).fit(cov_type='HC3')\n",
    "rate_comparison.append({\n",
    "    'Variable': 'Federal Funds Rate',\n",
    "    'R²': model_ffr.rsquared,\n",
    "    'Adj R²': model_ffr.rsquared_adj,\n",
    "    'Coefficient': model_ffr.params[1],  # Index 1 is first variable\n",
    "    'P-value': model_ffr.pvalues[1],  # Index 1 is first variable\n",
    "    'AIC': model_ffr.aic,\n",
    "    'BIC': model_ffr.bic\n",
    "})\n",
    "\n",
    "# Test alternative rates\n",
    "for rate_name in alt_rates.keys():\n",
    "    if rate_name in comparison_data.columns:\n",
    "        X_alt = comparison_data[[rate_name]].values\n",
    "        X_alt_const = sm.add_constant(X_alt)\n",
    "        model_alt = sm.OLS(y, X_alt_const).fit(cov_type='HC3')\n",
    "        rate_comparison.append({\n",
    "            'Variable': rate_name.replace('_', ' '),\n",
    "            'R²': model_alt.rsquared,\n",
    "            'Adj R²': model_alt.rsquared_adj,\n",
    "            'Coefficient': model_alt.params[1],  # Index 1 is first variable\n",
    "            'P-value': model_alt.pvalues[1],  # Index 1 is first variable\n",
    "            'AIC': model_alt.aic,\n",
    "            'BIC': model_alt.bic\n",
    "        })\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame(rate_comparison)\n",
    "comparison_df = comparison_df.sort_values('Adj R²', ascending=False)\n",
    "\n",
    "print(\"\\nResults (sorted by Adjusted R²):\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Identify best rate\n",
    "best_rate = comparison_df.iloc[0]\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"BEST INTEREST RATE VARIABLE: {best_rate['Variable']}\")\n",
    "print(f\"  Adjusted R² = {best_rate['Adj R²']:.4f}\")\n",
    "print(f\"  Coefficient = {best_rate['Coefficient']:.4f} (p = {best_rate['P-value']:.4f})\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Store best rate for use in refined model\n",
    "if best_rate['Variable'] == 'Federal Funds Rate':\n",
    "    selected_rate_var = 'fed_funds_change'\n",
    "    selected_rate_name = 'Federal Funds Rate'\n",
    "else:\n",
    "    # Map back to column name\n",
    "    selected_rate_var = best_rate['Variable'].replace(' ', '_')\n",
    "    selected_rate_name = best_rate['Variable']\n",
    "    # Update data with selected rate\n",
    "    if selected_rate_var in comparison_data.columns:\n",
    "        # Update data with selected rate using proper index alignment\n",
    "        # Drop duplicates from comparison_data to avoid reindex errors\n",
    "        comparison_clean = comparison_data[[selected_rate_var]].drop_duplicates()\n",
    "        data = data.join(comparison_clean, how='left')\n",
    "        # Also update fed_funds_change to use selected rate for consistency\n",
    "        data['fed_funds_change'] = data[selected_rate_var]\n",
    "\n",
    "print(f\"\\nSelected rate variable: {selected_rate_name} ({selected_rate_var})\")\n",
    "print(\"This will be used as the primary interest rate variable in the refined model.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interest_rate_selection_narrative",
   "metadata": {},
   "source": [
    "### Interest Rate Variable Selection: Empirical Testing and Model Refinement\n",
    "\n",
    "While the Federal Funds Rate has strong theoretical justification as the primary monetary policy tool affecting BNPL firms' funding costs, we empirically test alternative interest rate variables to ensure we select the specification that best captures BNPL excess return sensitivity. This approach balances theoretical coherence with empirical fit, recognizing that different interest rate proxies may more directly reflect BNPL firms' actual borrowing costs or consumer credit market conditions.\n",
    "\n",
    "We test four candidate interest rate variables: (1) **Federal Funds Rate**, the primary monetary policy tool; (2) **3-Month Treasury Rate**, a market-determined short-term risk-free rate closely related to commercial paper rates; (3) **Commercial Paper Rate**, which most directly reflects BNPL firms' wholesale funding costs; and (4) **Prime Rate**, a consumer lending benchmark that affects the credit markets where BNPL competes. Each variable is tested in a simple bivariate regression against BNPL excess returns, and we select the specification with the highest adjusted R² and strongest statistical significance.\n",
    "\n",
    "The empirical comparison reveals which interest rate variable provides the best fit for explaining BNPL excess returns. This finding informs our model specification by identifying whether BNPL firms are most sensitive to monetary policy rates (Federal Funds Rate), market-determined short-term rates (3-Month Treasury or Commercial Paper), or consumer credit market benchmarks (Prime Rate). The selected variable is then used as the primary explanatory variable in both the baseline and refined multi-factor models, ensuring that our analysis captures the most relevant interest rate channel affecting BNPL stock performance.\n",
    "\n",
    "This empirical selection process represents a key refinement of our modeling approach, moving beyond theoretical assumptions to data-driven specification. The coefficient on the selected interest rate variable in our regression models represents the sensitivity of BNPL excess returns to changes in that specific rate, controlling for other economic factors in the refined specification. This approach aligns with best practices in empirical finance, where model specification should be informed by both theoretical expectations and empirical evidence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
